{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T07:40:42.167971Z",
     "iopub.status.busy": "2023-02-21T07:40:42.167262Z",
     "iopub.status.idle": "2023-02-21T07:40:42.341062Z",
     "shell.execute_reply": "2023-02-21T07:40:42.339956Z",
     "shell.execute_reply.started": "2023-02-21T07:40:42.167926Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "from torchvision.models.vgg import vgg16\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import time\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T07:40:45.798974Z",
     "iopub.status.busy": "2023-02-21T07:40:45.798296Z",
     "iopub.status.idle": "2023-02-21T07:40:45.807275Z",
     "shell.execute_reply": "2023-02-21T07:40:45.806330Z",
     "shell.execute_reply.started": "2023-02-21T07:40:45.798939Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(1103)\n",
    "\n",
    "\n",
    "def populate_train_list(lowlight_images_path):\n",
    "    image_list_lowlight = glob.glob(lowlight_images_path + \"/*.jpg\")\n",
    "    \n",
    "    train_list = image_list_lowlight\n",
    "    random.shuffle(train_list)\n",
    "\n",
    "    return train_list\n",
    "\n",
    "\n",
    "\n",
    "class lowlight_loader(data.Dataset):\n",
    "\n",
    "    def __init__(self, lowlight_images_path):\n",
    "\n",
    "        self.train_list = populate_train_list(lowlight_images_path) \n",
    "        self.size = 256\n",
    "\n",
    "        self.data_list = self.train_list\n",
    "        print(\"Total training examples:\", len(self.train_list))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        data_lowlight_path = self.data_list[index]\n",
    "\n",
    "        data_lowlight = Image.open(data_lowlight_path)\n",
    "\n",
    "        data_lowlight = data_lowlight.resize((self.size,self.size), Image.Resampling.LANCZOS)\n",
    "\n",
    "        data_lowlight = (np.asarray(data_lowlight)/255.0) \n",
    "        data_lowlight = torch.from_numpy(data_lowlight).float()\n",
    "\n",
    "        return data_lowlight.permute(2,0,1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T07:40:48.242105Z",
     "iopub.status.busy": "2023-02-21T07:40:48.241733Z",
     "iopub.status.idle": "2023-02-21T07:40:48.257762Z",
     "shell.execute_reply": "2023-02-21T07:40:48.256457Z",
     "shell.execute_reply.started": "2023-02-21T07:40:48.242068Z"
    }
   },
   "outputs": [],
   "source": [
    "class enhance_net_nopool(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(enhance_net_nopool, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        number_f = 32\n",
    "        self.e_conv1 = nn.Conv2d(3,number_f,3,1,1,bias=True) \n",
    "        self.e_conv2 = nn.Conv2d(number_f,number_f,3,1,1,bias=True) \n",
    "        self.e_conv3 = nn.Conv2d(number_f,number_f,3,1,1,bias=True) \n",
    "        self.e_conv4 = nn.Conv2d(number_f,number_f,3,1,1,bias=True) \n",
    "        self.e_conv5 = nn.Conv2d(number_f*2,number_f,3,1,1,bias=True) \n",
    "        self.e_conv6 = nn.Conv2d(number_f*2,number_f,3,1,1,bias=True) \n",
    "        self.e_conv7 = nn.Conv2d(number_f*2,24,3,1,1,bias=True) \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2, stride=2, return_indices=False, ceil_mode=False)\n",
    "        self.upsample = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x1 = self.relu(self.e_conv1(x))\n",
    "        # p1 = self.maxpool(x1)\n",
    "        x2 = self.relu(self.e_conv2(x1))\n",
    "        # p2 = self.maxpool(x2)\n",
    "        x3 = self.relu(self.e_conv3(x2))\n",
    "        # p3 = self.maxpool(x3)\n",
    "        x4 = self.relu(self.e_conv4(x3))\n",
    "\n",
    "        x5 = self.relu(self.e_conv5(torch.cat([x3,x4],1)))\n",
    "        # x5 = self.upsample(x5)\n",
    "        x6 = self.relu(self.e_conv6(torch.cat([x2,x5],1)))\n",
    "\n",
    "        x_r = F.tanh(self.e_conv7(torch.cat([x1,x6],1)))\n",
    "        r1,r2,r3,r4,r5,r6,r7,r8 = torch.split(x_r, 3, dim=1)\n",
    "\n",
    "\n",
    "        x = x + r1*(torch.pow(x,2)-x)\n",
    "        x = x + r2*(torch.pow(x,2)-x)\n",
    "        x = x + r3*(torch.pow(x,2)-x)\n",
    "        enhance_image_1 = x + r4*(torch.pow(x,2)-x)\t\t\n",
    "        x = enhance_image_1 + r5*(torch.pow(enhance_image_1,2)-enhance_image_1)\t\t\n",
    "        x = x + r6*(torch.pow(x,2)-x)\t\n",
    "        x = x + r7*(torch.pow(x,2)-x)\n",
    "        enhance_image = x + r8*(torch.pow(x,2)-x)\n",
    "        r = torch.cat([r1,r2,r3,r4,r5,r6,r7,r8],1)\n",
    "        return enhance_image_1,enhance_image,r\n",
    "        #return enhance_image\n",
    "        #return r\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MYLOSS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T07:40:50.809655Z",
     "iopub.status.busy": "2023-02-21T07:40:50.809277Z",
     "iopub.status.idle": "2023-02-21T07:40:50.834749Z",
     "shell.execute_reply": "2023-02-21T07:40:50.832369Z",
     "shell.execute_reply.started": "2023-02-21T07:40:50.809622Z"
    }
   },
   "outputs": [],
   "source": [
    "class L_color(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(L_color, self).__init__()\n",
    "\n",
    "    def forward(self, x ):\n",
    "\n",
    "        b,c,h,w = x.shape\n",
    "\n",
    "        mean_rgb = torch.mean(x,[2,3],keepdim=True)\n",
    "        mr,mg, mb = torch.split(mean_rgb, 1, dim=1)\n",
    "        Drg = torch.pow(mr-mg,2)\n",
    "        Drb = torch.pow(mr-mb,2)\n",
    "        Dgb = torch.pow(mb-mg,2)\n",
    "        k = torch.pow(torch.pow(Drg,2) + torch.pow(Drb,2) + torch.pow(Dgb,2),0.5)\n",
    "\n",
    "\n",
    "        return k\n",
    "\n",
    "class L_spa(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(L_spa, self).__init__()\n",
    "        # print(1)kernel = torch.FloatTensor(kernel).unsqueeze(0).unsqueeze(0)\n",
    "        kernel_left = torch.FloatTensor( [[0,0,0],[-1,1,0],[0,0,0]]).to(device).unsqueeze(0).unsqueeze(0)\n",
    "        kernel_right = torch.FloatTensor( [[0,0,0],[0,1,-1],[0,0,0]]).to(device).unsqueeze(0).unsqueeze(0)\n",
    "        kernel_up = torch.FloatTensor( [[0,-1,0],[0,1, 0 ],[0,0,0]]).to(device).unsqueeze(0).unsqueeze(0)\n",
    "        kernel_down = torch.FloatTensor( [[0,0,0],[0,1, 0],[0,-1,0]]).to(device).unsqueeze(0).unsqueeze(0)\n",
    "        self.weight_left = nn.Parameter(data=kernel_left, requires_grad=False)\n",
    "        self.weight_right = nn.Parameter(data=kernel_right, requires_grad=False)\n",
    "        self.weight_up = nn.Parameter(data=kernel_up, requires_grad=False)\n",
    "        self.weight_down = nn.Parameter(data=kernel_down, requires_grad=False)\n",
    "        self.pool = nn.AvgPool2d(4)\n",
    "    def forward(self, org , enhance ):\n",
    "        b,c,h,w = org.shape\n",
    "\n",
    "        org_mean = torch.mean(org,1,keepdim=True)\n",
    "        enhance_mean = torch.mean(enhance,1,keepdim=True)\n",
    "\n",
    "        org_pool =  self.pool(org_mean)\t\t\t\n",
    "        enhance_pool = self.pool(enhance_mean)\t\n",
    "\n",
    "        weight_diff =torch.max(torch.FloatTensor([1]).to(device) + 10000*torch.min(org_pool - torch.FloatTensor([0.3]).to(device),torch.FloatTensor([0]).to(device)),torch.FloatTensor([0.5]).to(device))\n",
    "        E_1 = torch.mul(torch.sign(enhance_pool - torch.FloatTensor([0.5]).to(device)) ,enhance_pool-org_pool)\n",
    "\n",
    "\n",
    "        D_org_letf = F.conv2d(org_pool , self.weight_left, padding=1)\n",
    "        D_org_right = F.conv2d(org_pool , self.weight_right, padding=1)\n",
    "        D_org_up = F.conv2d(org_pool , self.weight_up, padding=1)\n",
    "        D_org_down = F.conv2d(org_pool , self.weight_down, padding=1)\n",
    "\n",
    "        D_enhance_letf = F.conv2d(enhance_pool , self.weight_left, padding=1)\n",
    "        D_enhance_right = F.conv2d(enhance_pool , self.weight_right, padding=1)\n",
    "        D_enhance_up = F.conv2d(enhance_pool , self.weight_up, padding=1)\n",
    "        D_enhance_down = F.conv2d(enhance_pool , self.weight_down, padding=1)\n",
    "\n",
    "        D_left = torch.pow(D_org_letf - D_enhance_letf,2)\n",
    "        D_right = torch.pow(D_org_right - D_enhance_right,2)\n",
    "        D_up = torch.pow(D_org_up - D_enhance_up,2)\n",
    "        D_down = torch.pow(D_org_down - D_enhance_down,2)\n",
    "        E = (D_left + D_right + D_up +D_down)\n",
    "        # E = 25*(D_left + D_right + D_up +D_down)\n",
    "\n",
    "        return E\n",
    "class L_exp(nn.Module):\n",
    "\n",
    "    def __init__(self,patch_size,mean_val):\n",
    "        super(L_exp, self).__init__()\n",
    "        # print(1)\n",
    "        self.pool = nn.AvgPool2d(patch_size)\n",
    "        self.mean_val = mean_val\n",
    "    def forward(self, x ):\n",
    "\n",
    "        b,c,h,w = x.shape\n",
    "        x = torch.mean(x,1,keepdim=True)\n",
    "        mean = self.pool(x)\n",
    "\n",
    "        d = torch.mean(torch.pow(mean- torch.FloatTensor([self.mean_val] ).to(device),2))\n",
    "        return d\n",
    "        \n",
    "class L_TV(nn.Module):\n",
    "    def __init__(self,TVLoss_weight=1):\n",
    "        super(L_TV,self).__init__()\n",
    "        self.TVLoss_weight = TVLoss_weight\n",
    "\n",
    "    def forward(self,x):\n",
    "        batch_size = x.size()[0]\n",
    "        h_x = x.size()[2]\n",
    "        w_x = x.size()[3]\n",
    "        count_h =  (x.size()[2]-1) * x.size()[3]\n",
    "        count_w = x.size()[2] * (x.size()[3] - 1)\n",
    "        h_tv = torch.pow((x[:,:,1:,:]-x[:,:,:h_x-1,:]),2).sum()\n",
    "        w_tv = torch.pow((x[:,:,:,1:]-x[:,:,:,:w_x-1]),2).sum()\n",
    "        return self.TVLoss_weight*2*(h_tv/count_h+w_tv/count_w)/batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gst_str = ('nvarguscamerasrc ! '\n",
    "            'video/x-raw(memory:NVMM), '\n",
    "            'width=(int)1280, height=(int)720, '\n",
    "            'format=(string)NV12, framerate=(fraction)30/1 ! '\n",
    "            'nvvidconv flip-method=0 ! '\n",
    "            'video/x-raw, width=(int){}, height=(int){}, '\n",
    "            'format=(string)BGRx ! '\n",
    "            'videoconvert ! appsink').format(1280, 720)  #width, height\n",
    "cap = cv2.VideoCapture(gst_str)\n",
    "if not cap.isOpened():\n",
    "   print('Failed to open camera!')\n",
    "flag = cap.isOpened()\n",
    "index = 1\n",
    "while (flag):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"Capture_Paizhao\", frame)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('s'):  # 按下s键，进入下面的保存图片操作\n",
    "        cv2.imwrite(\"./test_data/NEW/NEW\"+str(index)+\".jpg\", frame)\n",
    "        print(\"save \" + \"NEW\"+str(index) + \".jpg successfuly!\")\n",
    "        print(\"-------------------------\")\n",
    "        index += 1\n",
    "    elif k  & 0xFF == 27:  # 按下esc键，程序退出\n",
    "        break\n",
    "cap.release() # 释放摄像头\n",
    "cv2.destroyAllWindows()# 释放并销毁窗口"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vedio打开摄像头录制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T06:25:21.165147Z",
     "iopub.status.busy": "2023-02-21T06:25:21.164583Z",
     "iopub.status.idle": "2023-02-21T06:25:31.997751Z",
     "shell.execute_reply": "2023-02-21T06:25:31.996184Z",
     "shell.execute_reply.started": "2023-02-21T06:25:21.165113Z"
    }
   },
   "outputs": [],
   "source": [
    "gst_str = ('nvarguscamerasrc ! '\n",
    "            'video/x-raw(memory:NVMM), '\n",
    "            'width=(int)480, height=(int)640, '\n",
    "            'format=(string)NV12, framerate=(fraction)20/1 ! '\n",
    "            'nvvidconv flip-method=0 ! '\n",
    "            'video/x-raw, width=(int){}, height=(int){}, '\n",
    "            'format=(string)BGRx ! '\n",
    "            'videoconvert ! appsink').format(480, 640)  #width, height\n",
    "\n",
    "cap = cv2.VideoCapture(gst_str)\n",
    "if not cap.isOpened():\n",
    "   print('Failed to open camera!')\n",
    "flag = cap.isOpened()\n",
    "index = 1\n",
    "while (flag):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"Capture\", frame)\n",
    "    cv2.imwrite('/home/tx2/Zero-DCE/test_data/New_vedio/NewVedio%d.jpg'%index, frame)\n",
    "    index += 1\n",
    "    if cv2.waitKey(1) & 0xFF == 27 :\n",
    "        break \n",
    "cap.release() # 释放摄像头\n",
    "cv2.destroyAllWindows()# 释放并销毁窗口"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vedio选择TX2中路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.xticks([]), plt.yticks([]) # 隐藏x和y轴\n",
    "index=1\n",
    "#视频读取\n",
    "#cv2.VideoCapture可以捕获摄像头，用数字来控制不同的设备，例如0,1。\n",
    "#如果是视频文件，直接指定好路径即可。\n",
    "\n",
    "#VideoCapture()中参数是0，表示打开笔记本的内置摄像头。\n",
    "#video = cv.VideoCapture(0)\n",
    "\n",
    "#表示参数是视频文件路径则打开视频\n",
    "video = cv2.VideoCapture('/home/tx2/Zero-DCE/test_vedio/test.mp4')\n",
    "\n",
    "#检查是否正确打开isOpened()\n",
    "#循环读取每一帧\n",
    "while video.isOpened():\n",
    "    #video.read() : 一次读取视频中的每一帧，会返回两个值；\n",
    "    #res : 为bool类型表示这一帧是否真确读取，正确读取为True，如果文件读取到结尾，它的返回值就为False;\n",
    "    #frame : 表示这一帧的像素点数组\n",
    "    ret, frame = video.read()\n",
    "    if frame is None: \n",
    "        break\n",
    "    if ret == True:\n",
    "        cv2.imwrite('/home/tx2/Zero-DCE/test_data/Vedio_pic/Vedio%d.jpg'%index, frame)\n",
    "        index=index+1\n",
    "#         img_new2 = frame[:, :, ::-1]\n",
    "#         plt.imshow(img_new2)\n",
    "        cv2.imshow(\"result\", frame)\n",
    "    #100 ： 表示一帧等待一百毫秒在进入下一帧， 0xFF : 表示键入键 27 = esc\n",
    "    if cv2.waitKey(50) & 0xFF == 27 :\n",
    "        break \n",
    "#video.release()释放视频\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T07:47:06.374600Z",
     "iopub.status.busy": "2023-02-21T07:47:06.374222Z",
     "iopub.status.idle": "2023-02-21T07:47:09.694766Z",
     "shell.execute_reply": "2023-02-21T07:47:09.693705Z",
     "shell.execute_reply.started": "2023-02-21T07:47:06.374566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_data/New_vedio/NewVedio173.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tx2/.local/lib/python3.6/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7223942279815674\n",
      "./working/NewVedio173.jpg\n",
      "./test_data/New_vedio/NewVedio244.jpg\n",
      "0.005994558334350586\n",
      "./working/NewVedio244.jpg\n",
      "./test_data/New_vedio/NewVedio163.jpg\n",
      "0.006193876266479492\n",
      "./working/NewVedio163.jpg\n",
      "./test_data/New_vedio/NewVedio245.jpg\n",
      "0.006075143814086914\n",
      "./working/NewVedio245.jpg\n",
      "./test_data/New_vedio/NewVedio64.jpg\n",
      "0.006221294403076172\n",
      "./working/NewVedio64.jpg\n",
      "./test_data/New_vedio/NewVedio116.jpg\n",
      "0.0071642398834228516\n",
      "./working/NewVedio116.jpg\n",
      "./test_data/New_vedio/NewVedio193.jpg\n",
      "0.006154298782348633\n",
      "./working/NewVedio193.jpg\n",
      "./test_data/New_vedio/NewVedio100.jpg\n",
      "0.006048679351806641\n",
      "./working/NewVedio100.jpg\n",
      "./test_data/New_vedio/NewVedio180.jpg\n",
      "0.006140708923339844\n",
      "./working/NewVedio180.jpg\n",
      "./test_data/New_vedio/NewVedio118.jpg\n",
      "0.0062177181243896484\n",
      "./working/NewVedio118.jpg\n",
      "./test_data/New_vedio/NewVedio136.jpg\n",
      "0.006102800369262695\n",
      "./working/NewVedio136.jpg\n",
      "./test_data/New_vedio/NewVedio105.jpg\n",
      "0.006130218505859375\n",
      "./working/NewVedio105.jpg\n",
      "./test_data/New_vedio/NewVedio38.jpg\n",
      "0.008114814758300781\n",
      "./working/NewVedio38.jpg\n",
      "./test_data/New_vedio/NewVedio172.jpg\n",
      "0.006117820739746094\n",
      "./working/NewVedio172.jpg\n",
      "./test_data/New_vedio/NewVedio76.jpg\n",
      "0.006185293197631836\n",
      "./working/NewVedio76.jpg\n",
      "./test_data/New_vedio/NewVedio122.jpg\n",
      "0.006276845932006836\n",
      "./working/NewVedio122.jpg\n",
      "./test_data/New_vedio/NewVedio56.jpg\n",
      "0.006383657455444336\n",
      "./working/NewVedio56.jpg\n",
      "./test_data/New_vedio/NewVedio209.jpg\n",
      "0.006079912185668945\n",
      "./working/NewVedio209.jpg\n",
      "./test_data/New_vedio/NewVedio251.jpg\n",
      "0.006055593490600586\n",
      "./working/NewVedio251.jpg\n",
      "./test_data/New_vedio/NewVedio27.jpg\n",
      "0.0062716007232666016\n",
      "./working/NewVedio27.jpg\n",
      "./test_data/New_vedio/NewVedio114.jpg\n",
      "0.0061452388763427734\n",
      "./working/NewVedio114.jpg\n",
      "./test_data/New_vedio/NewVedio9.jpg\n",
      "0.00658106803894043\n",
      "./working/NewVedio9.jpg\n",
      "./test_data/New_vedio/NewVedio107.jpg\n",
      "0.006639957427978516\n",
      "./working/NewVedio107.jpg\n",
      "./test_data/New_vedio/NewVedio53.jpg\n",
      "0.006075859069824219\n",
      "./working/NewVedio53.jpg\n",
      "./test_data/New_vedio/NewVedio229.jpg\n",
      "0.00615382194519043\n",
      "./working/NewVedio229.jpg\n",
      "./test_data/New_vedio/NewVedio168.jpg\n",
      "0.011275768280029297\n",
      "./working/NewVedio168.jpg\n",
      "./test_data/New_vedio/NewVedio124.jpg\n",
      "0.006074666976928711\n",
      "./working/NewVedio124.jpg\n",
      "./test_data/New_vedio/NewVedio117.jpg\n",
      "0.006027698516845703\n",
      "./working/NewVedio117.jpg\n",
      "./test_data/New_vedio/NewVedio196.jpg\n",
      "0.006021738052368164\n",
      "./working/NewVedio196.jpg\n",
      "./test_data/New_vedio/NewVedio222.jpg\n",
      "0.006082057952880859\n",
      "./working/NewVedio222.jpg\n",
      "./test_data/New_vedio/NewVedio213.jpg\n",
      "0.006304740905761719\n",
      "./working/NewVedio213.jpg\n",
      "./test_data/New_vedio/NewVedio186.jpg\n",
      "0.00609898567199707\n",
      "./working/NewVedio186.jpg\n",
      "./test_data/New_vedio/NewVedio32.jpg\n",
      "0.0061681270599365234\n",
      "./working/NewVedio32.jpg\n",
      "./test_data/New_vedio/NewVedio217.jpg\n",
      "0.006079673767089844\n",
      "./working/NewVedio217.jpg\n",
      "./test_data/New_vedio/NewVedio5.jpg\n",
      "0.006220340728759766\n",
      "./working/NewVedio5.jpg\n",
      "./test_data/New_vedio/NewVedio187.jpg\n",
      "0.006109952926635742\n",
      "./working/NewVedio187.jpg\n",
      "./test_data/New_vedio/NewVedio138.jpg\n",
      "0.006251096725463867\n",
      "./working/NewVedio138.jpg\n",
      "./test_data/New_vedio/NewVedio183.jpg\n",
      "0.006037712097167969\n",
      "./working/NewVedio183.jpg\n",
      "./test_data/New_vedio/NewVedio202.jpg\n",
      "0.006040811538696289\n",
      "./working/NewVedio202.jpg\n",
      "./test_data/New_vedio/NewVedio247.jpg\n",
      "0.006186485290527344\n",
      "./working/NewVedio247.jpg\n",
      "./test_data/New_vedio/NewVedio239.jpg\n",
      "0.006142854690551758\n",
      "./working/NewVedio239.jpg\n",
      "./test_data/New_vedio/NewVedio140.jpg\n",
      "0.006822109222412109\n",
      "./working/NewVedio140.jpg\n",
      "./test_data/New_vedio/NewVedio181.jpg\n",
      "0.006403207778930664\n",
      "./working/NewVedio181.jpg\n",
      "./test_data/New_vedio/NewVedio241.jpg\n",
      "0.0062220096588134766\n",
      "./working/NewVedio241.jpg\n",
      "./test_data/New_vedio/NewVedio3.jpg\n",
      "0.006054878234863281\n",
      "./working/NewVedio3.jpg\n",
      "./test_data/New_vedio/NewVedio249.jpg\n",
      "0.0062885284423828125\n",
      "./working/NewVedio249.jpg\n",
      "./test_data/New_vedio/NewVedio63.jpg\n",
      "0.006085395812988281\n",
      "./working/NewVedio63.jpg\n",
      "./test_data/New_vedio/NewVedio73.jpg\n",
      "0.006166696548461914\n",
      "./working/NewVedio73.jpg\n",
      "./test_data/New_vedio/NewVedio59.jpg\n",
      "0.006159782409667969\n",
      "./working/NewVedio59.jpg\n",
      "./test_data/New_vedio/NewVedio104.jpg\n",
      "0.00972747802734375\n",
      "./working/NewVedio104.jpg\n",
      "./test_data/New_vedio/NewVedio150.jpg\n",
      "0.006076812744140625\n",
      "./working/NewVedio150.jpg\n",
      "./test_data/New_vedio/NewVedio141.jpg\n",
      "0.0061566829681396484\n",
      "./working/NewVedio141.jpg\n",
      "./test_data/New_vedio/NewVedio97.jpg\n",
      "0.0062503814697265625\n",
      "./working/NewVedio97.jpg\n",
      "./test_data/New_vedio/NewVedio160.jpg\n",
      "0.0072438716888427734\n",
      "./working/NewVedio160.jpg\n",
      "./test_data/New_vedio/NewVedio182.jpg\n",
      "0.012696266174316406\n",
      "./working/NewVedio182.jpg\n",
      "./test_data/New_vedio/NewVedio177.jpg\n",
      "0.010080337524414062\n",
      "./working/NewVedio177.jpg\n",
      "./test_data/New_vedio/NewVedio156.jpg\n",
      "0.0070879459381103516\n",
      "./working/NewVedio156.jpg\n",
      "./test_data/New_vedio/NewVedio112.jpg\n",
      "0.0065042972564697266\n",
      "./working/NewVedio112.jpg\n",
      "./test_data/New_vedio/NewVedio34.jpg\n",
      "0.006882905960083008\n",
      "./working/NewVedio34.jpg\n",
      "./test_data/New_vedio/NewVedio2.jpg\n",
      "0.009067296981811523\n",
      "./working/NewVedio2.jpg\n",
      "./test_data/New_vedio/NewVedio60.jpg\n",
      "0.006312131881713867\n",
      "./working/NewVedio60.jpg\n",
      "./test_data/New_vedio/NewVedio62.jpg\n",
      "0.006690263748168945\n",
      "./working/NewVedio62.jpg\n",
      "./test_data/New_vedio/NewVedio30.jpg\n",
      "0.006111860275268555\n",
      "./working/NewVedio30.jpg\n",
      "./test_data/New_vedio/NewVedio75.jpg\n",
      "0.006638526916503906\n",
      "./working/NewVedio75.jpg\n",
      "./test_data/New_vedio/NewVedio169.jpg\n",
      "0.006097555160522461\n",
      "./working/NewVedio169.jpg\n",
      "./test_data/New_vedio/NewVedio67.jpg\n",
      "0.0072095394134521484\n",
      "./working/NewVedio67.jpg\n",
      "./test_data/New_vedio/NewVedio224.jpg\n",
      "0.006563425064086914\n",
      "./working/NewVedio224.jpg\n",
      "./test_data/New_vedio/NewVedio26.jpg\n",
      "0.006131172180175781\n",
      "./working/NewVedio26.jpg\n",
      "./test_data/New_vedio/NewVedio96.jpg\n",
      "0.006139993667602539\n",
      "./working/NewVedio96.jpg\n",
      "./test_data/New_vedio/NewVedio206.jpg\n",
      "0.006191253662109375\n",
      "./working/NewVedio206.jpg\n",
      "./test_data/New_vedio/NewVedio92.jpg\n",
      "0.00965261459350586\n",
      "./working/NewVedio92.jpg\n",
      "./test_data/New_vedio/NewVedio99.jpg\n",
      "0.006844520568847656\n",
      "./working/NewVedio99.jpg\n",
      "./test_data/New_vedio/NewVedio243.jpg\n",
      "0.005997419357299805\n",
      "./working/NewVedio243.jpg\n",
      "./test_data/New_vedio/NewVedio232.jpg\n",
      "0.006097316741943359\n",
      "./working/NewVedio232.jpg\n",
      "./test_data/New_vedio/NewVedio6.jpg\n",
      "0.008932352066040039\n",
      "./working/NewVedio6.jpg\n",
      "./test_data/New_vedio/NewVedio74.jpg\n",
      "0.009935379028320312\n",
      "./working/NewVedio74.jpg\n",
      "./test_data/New_vedio/NewVedio20.jpg\n",
      "0.007796287536621094\n",
      "./working/NewVedio20.jpg\n",
      "./test_data/New_vedio/NewVedio39.jpg\n",
      "0.006384849548339844\n",
      "./working/NewVedio39.jpg\n",
      "./test_data/New_vedio/NewVedio102.jpg\n",
      "0.01007986068725586\n",
      "./working/NewVedio102.jpg\n",
      "./test_data/New_vedio/NewVedio44.jpg\n",
      "0.007123708724975586\n",
      "./working/NewVedio44.jpg\n",
      "./test_data/New_vedio/NewVedio25.jpg\n",
      "0.0065479278564453125\n",
      "./working/NewVedio25.jpg\n",
      "./test_data/New_vedio/NewVedio203.jpg\n",
      "0.010123968124389648\n",
      "./working/NewVedio203.jpg\n",
      "./test_data/New_vedio/NewVedio57.jpg\n",
      "0.006756782531738281\n",
      "./working/NewVedio57.jpg\n",
      "./test_data/New_vedio/NewVedio29.jpg\n",
      "0.00836491584777832\n",
      "./working/NewVedio29.jpg\n",
      "./test_data/New_vedio/NewVedio225.jpg\n",
      "0.005970954895019531\n",
      "./working/NewVedio225.jpg\n",
      "./test_data/New_vedio/NewVedio134.jpg\n",
      "0.01195836067199707\n",
      "./working/NewVedio134.jpg\n",
      "./test_data/New_vedio/NewVedio221.jpg\n",
      "0.006203174591064453\n",
      "./working/NewVedio221.jpg\n",
      "./test_data/New_vedio/NewVedio31.jpg\n",
      "0.006302356719970703\n",
      "./working/NewVedio31.jpg\n",
      "./test_data/New_vedio/NewVedio238.jpg\n",
      "0.006228446960449219\n",
      "./working/NewVedio238.jpg\n",
      "./test_data/New_vedio/NewVedio47.jpg\n",
      "0.01100301742553711\n",
      "./working/NewVedio47.jpg\n",
      "./test_data/New_vedio/NewVedio184.jpg\n",
      "0.006409406661987305\n",
      "./working/NewVedio184.jpg\n",
      "./test_data/New_vedio/NewVedio68.jpg\n",
      "0.011142253875732422\n",
      "./working/NewVedio68.jpg\n",
      "./test_data/New_vedio/NewVedio48.jpg\n",
      "0.00640106201171875\n",
      "./working/NewVedio48.jpg\n",
      "./test_data/New_vedio/NewVedio153.jpg\n",
      "0.00621342658996582\n",
      "./working/NewVedio153.jpg\n",
      "./test_data/New_vedio/NewVedio120.jpg\n",
      "0.006910800933837891\n",
      "./working/NewVedio120.jpg\n",
      "./test_data/New_vedio/NewVedio1.jpg\n",
      "0.005997657775878906\n",
      "./working/NewVedio1.jpg\n",
      "./test_data/New_vedio/NewVedio143.jpg\n",
      "0.01141214370727539\n",
      "./working/NewVedio143.jpg\n",
      "./test_data/New_vedio/NewVedio201.jpg\n",
      "0.01191568374633789\n",
      "./working/NewVedio201.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_data/New_vedio/NewVedio33.jpg\n",
      "0.006523609161376953\n",
      "./working/NewVedio33.jpg\n",
      "./test_data/New_vedio/NewVedio70.jpg\n",
      "0.011472225189208984\n",
      "./working/NewVedio70.jpg\n",
      "./test_data/New_vedio/NewVedio216.jpg\n",
      "0.012633323669433594\n",
      "./working/NewVedio216.jpg\n",
      "./test_data/New_vedio/NewVedio157.jpg\n",
      "0.007355690002441406\n",
      "./working/NewVedio157.jpg\n",
      "./test_data/New_vedio/NewVedio218.jpg\n",
      "0.01129293441772461\n",
      "./working/NewVedio218.jpg\n",
      "./test_data/New_vedio/NewVedio219.jpg\n",
      "0.00631403923034668\n",
      "./working/NewVedio219.jpg\n",
      "./test_data/New_vedio/NewVedio98.jpg\n",
      "0.00760650634765625\n",
      "./working/NewVedio98.jpg\n",
      "./test_data/New_vedio/NewVedio126.jpg\n",
      "0.0060863494873046875\n",
      "./working/NewVedio126.jpg\n",
      "./test_data/New_vedio/NewVedio37.jpg\n",
      "0.007130622863769531\n",
      "./working/NewVedio37.jpg\n",
      "./test_data/New_vedio/NewVedio95.jpg\n",
      "0.006699323654174805\n",
      "./working/NewVedio95.jpg\n",
      "./test_data/New_vedio/NewVedio69.jpg\n",
      "0.00846719741821289\n",
      "./working/NewVedio69.jpg\n",
      "./test_data/New_vedio/NewVedio211.jpg\n",
      "0.007510185241699219\n",
      "./working/NewVedio211.jpg\n",
      "./test_data/New_vedio/NewVedio28.jpg\n",
      "0.008864879608154297\n",
      "./working/NewVedio28.jpg\n",
      "./test_data/New_vedio/NewVedio129.jpg\n",
      "0.006279468536376953\n",
      "./working/NewVedio129.jpg\n",
      "./test_data/New_vedio/NewVedio144.jpg\n",
      "0.012100696563720703\n",
      "./working/NewVedio144.jpg\n",
      "./test_data/New_vedio/NewVedio165.jpg\n",
      "0.00611114501953125\n",
      "./working/NewVedio165.jpg\n",
      "./test_data/New_vedio/NewVedio236.jpg\n",
      "0.0060155391693115234\n",
      "./working/NewVedio236.jpg\n",
      "./test_data/New_vedio/NewVedio195.jpg\n",
      "0.01068878173828125\n",
      "./working/NewVedio195.jpg\n",
      "./test_data/New_vedio/NewVedio17.jpg\n",
      "0.007407665252685547\n",
      "./working/NewVedio17.jpg\n",
      "./test_data/New_vedio/NewVedio208.jpg\n",
      "0.007600069046020508\n",
      "./working/NewVedio208.jpg\n",
      "./test_data/New_vedio/NewVedio142.jpg\n",
      "0.008710861206054688\n",
      "./working/NewVedio142.jpg\n",
      "./test_data/New_vedio/NewVedio52.jpg\n",
      "0.008772611618041992\n",
      "./working/NewVedio52.jpg\n",
      "./test_data/New_vedio/NewVedio149.jpg\n",
      "0.00623011589050293\n",
      "./working/NewVedio149.jpg\n",
      "./test_data/New_vedio/NewVedio77.jpg\n",
      "0.0075457096099853516\n",
      "./working/NewVedio77.jpg\n",
      "./test_data/New_vedio/NewVedio65.jpg\n",
      "0.005976200103759766\n",
      "./working/NewVedio65.jpg\n",
      "./test_data/New_vedio/NewVedio166.jpg\n",
      "0.011481046676635742\n",
      "./working/NewVedio166.jpg\n",
      "./test_data/New_vedio/NewVedio91.jpg\n",
      "0.008767127990722656\n",
      "./working/NewVedio91.jpg\n",
      "./test_data/New_vedio/NewVedio167.jpg\n",
      "0.008391141891479492\n",
      "./working/NewVedio167.jpg\n",
      "./test_data/New_vedio/NewVedio207.jpg\n",
      "0.009972095489501953\n",
      "./working/NewVedio207.jpg\n",
      "./test_data/New_vedio/NewVedio190.jpg\n",
      "0.007643938064575195\n",
      "./working/NewVedio190.jpg\n",
      "./test_data/New_vedio/NewVedio41.jpg\n",
      "0.006186246871948242\n",
      "./working/NewVedio41.jpg\n",
      "./test_data/New_vedio/NewVedio151.jpg\n",
      "0.006106853485107422\n",
      "./working/NewVedio151.jpg\n",
      "./test_data/New_vedio/NewVedio191.jpg\n",
      "0.008167505264282227\n",
      "./working/NewVedio191.jpg\n",
      "./test_data/New_vedio/NewVedio135.jpg\n",
      "0.006101846694946289\n",
      "./working/NewVedio135.jpg\n",
      "./test_data/New_vedio/NewVedio13.jpg\n",
      "0.009884119033813477\n",
      "./working/NewVedio13.jpg\n",
      "./test_data/New_vedio/NewVedio7.jpg\n",
      "0.006810665130615234\n",
      "./working/NewVedio7.jpg\n",
      "./test_data/New_vedio/NewVedio10.jpg\n",
      "0.0063936710357666016\n",
      "./working/NewVedio10.jpg\n",
      "./test_data/New_vedio/NewVedio198.jpg\n",
      "0.013064384460449219\n",
      "./working/NewVedio198.jpg\n",
      "./test_data/New_vedio/NewVedio94.jpg\n",
      "0.012753963470458984\n",
      "./working/NewVedio94.jpg\n",
      "./test_data/New_vedio/NewVedio125.jpg\n",
      "0.006216764450073242\n",
      "./working/NewVedio125.jpg\n",
      "./test_data/New_vedio/NewVedio83.jpg\n",
      "0.011644124984741211\n",
      "./working/NewVedio83.jpg\n",
      "./test_data/New_vedio/NewVedio61.jpg\n",
      "0.006151676177978516\n",
      "./working/NewVedio61.jpg\n",
      "./test_data/New_vedio/NewVedio36.jpg\n",
      "0.015510797500610352\n",
      "./working/NewVedio36.jpg\n",
      "./test_data/New_vedio/NewVedio212.jpg\n",
      "0.010524749755859375\n",
      "./working/NewVedio212.jpg\n",
      "./test_data/New_vedio/NewVedio14.jpg\n",
      "0.010324716567993164\n",
      "./working/NewVedio14.jpg\n",
      "./test_data/New_vedio/NewVedio81.jpg\n",
      "0.00667119026184082\n",
      "./working/NewVedio81.jpg\n",
      "./test_data/New_vedio/NewVedio8.jpg\n",
      "0.006994009017944336\n",
      "./working/NewVedio8.jpg\n",
      "./test_data/New_vedio/NewVedio106.jpg\n",
      "0.006314754486083984\n",
      "./working/NewVedio106.jpg\n",
      "./test_data/New_vedio/NewVedio18.jpg\n",
      "0.008526325225830078\n",
      "./working/NewVedio18.jpg\n",
      "./test_data/New_vedio/NewVedio250.jpg\n",
      "0.00927877426147461\n",
      "./working/NewVedio250.jpg\n",
      "./test_data/New_vedio/NewVedio89.jpg\n",
      "0.01093912124633789\n",
      "./working/NewVedio89.jpg\n",
      "./test_data/New_vedio/NewVedio175.jpg\n",
      "0.006095409393310547\n",
      "./working/NewVedio175.jpg\n",
      "./test_data/New_vedio/NewVedio55.jpg\n",
      "0.006047964096069336\n",
      "./working/NewVedio55.jpg\n",
      "./test_data/New_vedio/NewVedio115.jpg\n",
      "0.0060214996337890625\n",
      "./working/NewVedio115.jpg\n",
      "./test_data/New_vedio/NewVedio199.jpg\n",
      "0.006561279296875\n",
      "./working/NewVedio199.jpg\n",
      "./test_data/New_vedio/NewVedio158.jpg\n",
      "0.006497383117675781\n",
      "./working/NewVedio158.jpg\n",
      "./test_data/New_vedio/NewVedio161.jpg\n",
      "0.0060253143310546875\n",
      "./working/NewVedio161.jpg\n",
      "./test_data/New_vedio/NewVedio164.jpg\n",
      "0.006033420562744141\n",
      "./working/NewVedio164.jpg\n",
      "./test_data/New_vedio/NewVedio58.jpg\n",
      "0.006003856658935547\n",
      "./working/NewVedio58.jpg\n",
      "./test_data/New_vedio/NewVedio22.jpg\n",
      "0.006423473358154297\n",
      "./working/NewVedio22.jpg\n",
      "./test_data/New_vedio/NewVedio148.jpg\n",
      "0.006112337112426758\n",
      "./working/NewVedio148.jpg\n",
      "./test_data/New_vedio/NewVedio246.jpg\n",
      "0.009158849716186523\n",
      "./working/NewVedio246.jpg\n",
      "./test_data/New_vedio/NewVedio78.jpg\n",
      "0.006069183349609375\n",
      "./working/NewVedio78.jpg\n",
      "./test_data/New_vedio/NewVedio127.jpg\n",
      "0.010787248611450195\n",
      "./working/NewVedio127.jpg\n",
      "./test_data/New_vedio/NewVedio233.jpg\n",
      "0.006154298782348633\n",
      "./working/NewVedio233.jpg\n",
      "./test_data/New_vedio/NewVedio252.jpg\n",
      "0.0064051151275634766\n",
      "./working/NewVedio252.jpg\n",
      "./test_data/New_vedio/NewVedio80.jpg\n",
      "0.006899595260620117\n",
      "./working/NewVedio80.jpg\n",
      "./test_data/New_vedio/NewVedio128.jpg\n",
      "0.006498098373413086\n",
      "./working/NewVedio128.jpg\n",
      "./test_data/New_vedio/NewVedio179.jpg\n",
      "0.010113716125488281\n",
      "./working/NewVedio179.jpg\n",
      "./test_data/New_vedio/NewVedio230.jpg\n",
      "0.006899356842041016\n",
      "./working/NewVedio230.jpg\n",
      "./test_data/New_vedio/NewVedio145.jpg\n",
      "0.008226633071899414\n",
      "./working/NewVedio145.jpg\n",
      "./test_data/New_vedio/NewVedio43.jpg\n",
      "0.009609460830688477\n",
      "./working/NewVedio43.jpg\n",
      "./test_data/New_vedio/NewVedio170.jpg\n",
      "0.005944490432739258\n",
      "./working/NewVedio170.jpg\n",
      "./test_data/New_vedio/NewVedio12.jpg\n",
      "0.008143424987792969\n",
      "./working/NewVedio12.jpg\n",
      "./test_data/New_vedio/NewVedio50.jpg\n",
      "0.005991458892822266\n",
      "./working/NewVedio50.jpg\n",
      "./test_data/New_vedio/NewVedio176.jpg\n",
      "0.0059511661529541016\n",
      "./working/NewVedio176.jpg\n",
      "./test_data/New_vedio/NewVedio132.jpg\n",
      "0.005982160568237305\n",
      "./working/NewVedio132.jpg\n",
      "./test_data/New_vedio/NewVedio66.jpg\n",
      "0.00628662109375\n",
      "./working/NewVedio66.jpg\n",
      "./test_data/New_vedio/NewVedio154.jpg\n",
      "0.0060672760009765625\n",
      "./working/NewVedio154.jpg\n",
      "./test_data/New_vedio/NewVedio24.jpg\n",
      "0.010019063949584961\n",
      "./working/NewVedio24.jpg\n",
      "./test_data/New_vedio/NewVedio192.jpg\n",
      "0.006152629852294922\n",
      "./working/NewVedio192.jpg\n",
      "./test_data/New_vedio/NewVedio72.jpg\n",
      "0.006179094314575195\n",
      "./working/NewVedio72.jpg\n",
      "./test_data/New_vedio/NewVedio234.jpg\n",
      "0.006094455718994141\n",
      "./working/NewVedio234.jpg\n",
      "./test_data/New_vedio/NewVedio121.jpg\n",
      "0.006203174591064453\n",
      "./working/NewVedio121.jpg\n",
      "./test_data/New_vedio/NewVedio84.jpg\n",
      "0.006550788879394531\n",
      "./working/NewVedio84.jpg\n",
      "./test_data/New_vedio/NewVedio215.jpg\n",
      "0.006306171417236328\n",
      "./working/NewVedio215.jpg\n",
      "./test_data/New_vedio/NewVedio152.jpg\n",
      "0.0071773529052734375\n",
      "./working/NewVedio152.jpg\n",
      "./test_data/New_vedio/NewVedio108.jpg\n",
      "0.006155967712402344\n",
      "./working/NewVedio108.jpg\n",
      "./test_data/New_vedio/NewVedio214.jpg\n",
      "0.006224155426025391\n",
      "./working/NewVedio214.jpg\n",
      "./test_data/New_vedio/NewVedio42.jpg\n",
      "0.006161689758300781\n",
      "./working/NewVedio42.jpg\n",
      "./test_data/New_vedio/NewVedio189.jpg\n",
      "0.006188869476318359\n",
      "./working/NewVedio189.jpg\n",
      "./test_data/New_vedio/NewVedio54.jpg\n",
      "0.006207704544067383\n",
      "./working/NewVedio54.jpg\n",
      "./test_data/New_vedio/NewVedio49.jpg\n",
      "0.006289243698120117\n",
      "./working/NewVedio49.jpg\n",
      "./test_data/New_vedio/NewVedio226.jpg\n",
      "0.006160259246826172\n",
      "./working/NewVedio226.jpg\n",
      "./test_data/New_vedio/NewVedio123.jpg\n",
      "0.0062122344970703125\n",
      "./working/NewVedio123.jpg\n",
      "./test_data/New_vedio/NewVedio79.jpg\n",
      "0.0061223506927490234\n",
      "./working/NewVedio79.jpg\n",
      "./test_data/New_vedio/NewVedio235.jpg\n",
      "0.006284236907958984\n",
      "./working/NewVedio235.jpg\n",
      "./test_data/New_vedio/NewVedio147.jpg\n",
      "0.006115436553955078\n",
      "./working/NewVedio147.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_data/New_vedio/NewVedio205.jpg\n",
      "0.006338357925415039\n",
      "./working/NewVedio205.jpg\n",
      "./test_data/New_vedio/NewVedio101.jpg\n",
      "0.006169795989990234\n",
      "./working/NewVedio101.jpg\n",
      "./test_data/New_vedio/NewVedio248.jpg\n",
      "0.00606083869934082\n",
      "./working/NewVedio248.jpg\n",
      "./test_data/New_vedio/NewVedio86.jpg\n",
      "0.0060079097747802734\n",
      "./working/NewVedio86.jpg\n",
      "./test_data/New_vedio/NewVedio45.jpg\n",
      "0.0060117244720458984\n",
      "./working/NewVedio45.jpg\n",
      "./test_data/New_vedio/NewVedio85.jpg\n",
      "0.006251811981201172\n",
      "./working/NewVedio85.jpg\n",
      "./test_data/New_vedio/NewVedio110.jpg\n",
      "0.006284475326538086\n",
      "./working/NewVedio110.jpg\n",
      "./test_data/New_vedio/NewVedio46.jpg\n",
      "0.006222724914550781\n",
      "./working/NewVedio46.jpg\n",
      "./test_data/New_vedio/NewVedio40.jpg\n",
      "0.006155967712402344\n",
      "./working/NewVedio40.jpg\n",
      "./test_data/New_vedio/NewVedio82.jpg\n",
      "0.006742715835571289\n",
      "./working/NewVedio82.jpg\n",
      "./test_data/New_vedio/NewVedio137.jpg\n",
      "0.006380558013916016\n",
      "./working/NewVedio137.jpg\n",
      "./test_data/New_vedio/NewVedio155.jpg\n",
      "0.012650012969970703\n",
      "./working/NewVedio155.jpg\n",
      "./test_data/New_vedio/NewVedio87.jpg\n",
      "0.006369829177856445\n",
      "./working/NewVedio87.jpg\n",
      "./test_data/New_vedio/NewVedio103.jpg\n",
      "0.0068166255950927734\n",
      "./working/NewVedio103.jpg\n",
      "./test_data/New_vedio/NewVedio19.jpg\n",
      "0.00609898567199707\n",
      "./working/NewVedio19.jpg\n",
      "./test_data/New_vedio/NewVedio11.jpg\n",
      "0.006008148193359375\n",
      "./working/NewVedio11.jpg\n",
      "./test_data/New_vedio/NewVedio240.jpg\n",
      "0.00629115104675293\n",
      "./working/NewVedio240.jpg\n",
      "./test_data/New_vedio/NewVedio16.jpg\n",
      "0.0063762664794921875\n",
      "./working/NewVedio16.jpg\n",
      "./test_data/New_vedio/NewVedio194.jpg\n",
      "0.0061991214752197266\n",
      "./working/NewVedio194.jpg\n",
      "./test_data/New_vedio/NewVedio210.jpg\n",
      "0.006256103515625\n",
      "./working/NewVedio210.jpg\n",
      "./test_data/New_vedio/NewVedio159.jpg\n",
      "0.006032705307006836\n",
      "./working/NewVedio159.jpg\n",
      "./test_data/New_vedio/NewVedio15.jpg\n",
      "0.006021022796630859\n",
      "./working/NewVedio15.jpg\n",
      "./test_data/New_vedio/NewVedio237.jpg\n",
      "0.0059545040130615234\n",
      "./working/NewVedio237.jpg\n",
      "./test_data/New_vedio/NewVedio174.jpg\n",
      "0.0067272186279296875\n",
      "./working/NewVedio174.jpg\n",
      "./test_data/New_vedio/NewVedio223.jpg\n",
      "0.006157636642456055\n",
      "./working/NewVedio223.jpg\n",
      "./test_data/New_vedio/NewVedio242.jpg\n",
      "0.0067920684814453125\n",
      "./working/NewVedio242.jpg\n",
      "./test_data/New_vedio/NewVedio139.jpg\n",
      "0.006195783615112305\n",
      "./working/NewVedio139.jpg\n",
      "./test_data/New_vedio/NewVedio109.jpg\n",
      "0.006330966949462891\n",
      "./working/NewVedio109.jpg\n",
      "./test_data/New_vedio/NewVedio146.jpg\n",
      "0.006149768829345703\n",
      "./working/NewVedio146.jpg\n",
      "./test_data/New_vedio/NewVedio133.jpg\n",
      "0.006307125091552734\n",
      "./working/NewVedio133.jpg\n",
      "./test_data/New_vedio/NewVedio113.jpg\n",
      "0.006018400192260742\n",
      "./working/NewVedio113.jpg\n",
      "./test_data/New_vedio/NewVedio35.jpg\n",
      "0.006165266036987305\n",
      "./working/NewVedio35.jpg\n",
      "./test_data/New_vedio/NewVedio21.jpg\n",
      "0.006088733673095703\n",
      "./working/NewVedio21.jpg\n",
      "./test_data/New_vedio/NewVedio51.jpg\n",
      "0.006078243255615234\n",
      "./working/NewVedio51.jpg\n",
      "./test_data/New_vedio/NewVedio220.jpg\n",
      "0.006256818771362305\n",
      "./working/NewVedio220.jpg\n",
      "./test_data/New_vedio/NewVedio178.jpg\n",
      "0.006003379821777344\n",
      "./working/NewVedio178.jpg\n",
      "./test_data/New_vedio/NewVedio93.jpg\n",
      "0.006132364273071289\n",
      "./working/NewVedio93.jpg\n",
      "./test_data/New_vedio/NewVedio188.jpg\n",
      "0.00608062744140625\n",
      "./working/NewVedio188.jpg\n",
      "./test_data/New_vedio/NewVedio200.jpg\n",
      "0.006017923355102539\n",
      "./working/NewVedio200.jpg\n",
      "./test_data/New_vedio/NewVedio204.jpg\n",
      "0.006082773208618164\n",
      "./working/NewVedio204.jpg\n",
      "./test_data/New_vedio/NewVedio231.jpg\n",
      "0.005993366241455078\n",
      "./working/NewVedio231.jpg\n",
      "./test_data/New_vedio/NewVedio185.jpg\n",
      "0.006083011627197266\n",
      "./working/NewVedio185.jpg\n",
      "./test_data/New_vedio/NewVedio4.jpg\n",
      "0.0062673091888427734\n",
      "./working/NewVedio4.jpg\n",
      "./test_data/New_vedio/NewVedio171.jpg\n",
      "0.006049156188964844\n",
      "./working/NewVedio171.jpg\n",
      "./test_data/New_vedio/NewVedio162.jpg\n",
      "0.00628662109375\n",
      "./working/NewVedio162.jpg\n",
      "./test_data/New_vedio/NewVedio130.jpg\n",
      "0.006752967834472656\n",
      "./working/NewVedio130.jpg\n",
      "./test_data/New_vedio/NewVedio228.jpg\n",
      "0.006064176559448242\n",
      "./working/NewVedio228.jpg\n",
      "./test_data/New_vedio/NewVedio197.jpg\n",
      "0.006459712982177734\n",
      "./working/NewVedio197.jpg\n",
      "./test_data/New_vedio/NewVedio227.jpg\n",
      "0.0065097808837890625\n",
      "./working/NewVedio227.jpg\n",
      "./test_data/New_vedio/NewVedio88.jpg\n",
      "0.006256103515625\n",
      "./working/NewVedio88.jpg\n",
      "./test_data/New_vedio/NewVedio90.jpg\n",
      "0.00596928596496582\n",
      "./working/NewVedio90.jpg\n",
      "./test_data/New_vedio/NewVedio131.jpg\n",
      "0.0062673091888427734\n",
      "./working/NewVedio131.jpg\n",
      "./test_data/New_vedio/NewVedio111.jpg\n",
      "0.006122112274169922\n",
      "./working/NewVedio111.jpg\n",
      "./test_data/New_vedio/NewVedio71.jpg\n",
      "0.006242275238037109\n",
      "./working/NewVedio71.jpg\n",
      "./test_data/New_vedio/NewVedio119.jpg\n",
      "0.006212472915649414\n",
      "./working/NewVedio119.jpg\n",
      "./test_data/New_vedio/NewVedio23.jpg\n",
      "0.006868124008178711\n",
      "./working/NewVedio23.jpg\n",
      "./test_data/NEW/NEW2.jpg\n",
      "0.006048679351806641\n",
      "./working/NEW2.jpg\n",
      "./test_data/NEW/NEW3.jpg\n",
      "0.006040096282958984\n",
      "./working/NEW3.jpg\n",
      "./test_data/NEW/NEW1.jpg\n",
      "0.00621342658996582\n",
      "./working/NEW1.jpg\n",
      "./test_data/LIME/7.bmp\n",
      "0.007854461669921875\n",
      "./working/7.bmp\n",
      "./test_data/LIME/9.bmp\n",
      "0.011324167251586914\n",
      "./working/9.bmp\n",
      "./test_data/LIME/8.bmp\n",
      "0.007983207702636719\n",
      "./working/8.bmp\n",
      "./test_data/LIME/3.bmp\n",
      "0.007877588272094727\n",
      "./working/3.bmp\n",
      "./test_data/LIME/5.bmp\n",
      "24.190043449401855\n",
      "./working/5.bmp\n",
      "./test_data/LIME/2.bmp\n",
      "0.29262804985046387\n",
      "./working/2.bmp\n",
      "./test_data/LIME/10.bmp\n",
      "0.008405923843383789\n",
      "./working/10.bmp\n",
      "./test_data/LIME/6.bmp\n",
      "0.007747173309326172\n",
      "./working/6.bmp\n",
      "./test_data/LIME/4.bmp\n",
      "0.009802818298339844\n",
      "./working/4.bmp\n",
      "./test_data/LIME/1.bmp\n",
      "0.0077631473541259766\n",
      "./working/1.bmp\n",
      "./test_data/Vedio_pic/Vedio149.jpg\n",
      "0.007460117340087891\n",
      "./working/Vedio149.jpg\n",
      "./test_data/Vedio_pic/Vedio86.jpg\n",
      "0.006329059600830078\n",
      "./working/Vedio86.jpg\n",
      "./test_data/Vedio_pic/Vedio109.jpg\n",
      "0.005963802337646484\n",
      "./working/Vedio109.jpg\n",
      "./test_data/Vedio_pic/Vedio58.jpg\n",
      "0.006361484527587891\n",
      "./working/Vedio58.jpg\n",
      "./test_data/Vedio_pic/Vedio140.jpg\n",
      "0.005944967269897461\n",
      "./working/Vedio140.jpg\n",
      "./test_data/Vedio_pic/Vedio59.jpg\n",
      "0.005957603454589844\n",
      "./working/Vedio59.jpg\n",
      "./test_data/Vedio_pic/Vedio65.jpg\n",
      "0.0068111419677734375\n",
      "./working/Vedio65.jpg\n",
      "./test_data/Vedio_pic/Vedio19.jpg\n",
      "0.005991458892822266\n",
      "./working/Vedio19.jpg\n",
      "./test_data/Vedio_pic/Vedio41.jpg\n",
      "0.006481647491455078\n",
      "./working/Vedio41.jpg\n",
      "./test_data/Vedio_pic/Vedio96.jpg\n",
      "0.006556510925292969\n",
      "./working/Vedio96.jpg\n",
      "./test_data/Vedio_pic/Vedio119.jpg\n",
      "0.006372690200805664\n",
      "./working/Vedio119.jpg\n",
      "./test_data/Vedio_pic/Vedio42.jpg\n",
      "0.006468772888183594\n",
      "./working/Vedio42.jpg\n",
      "./test_data/Vedio_pic/Vedio81.jpg\n",
      "0.006125211715698242\n",
      "./working/Vedio81.jpg\n",
      "./test_data/Vedio_pic/Vedio116.jpg\n",
      "0.006695270538330078\n",
      "./working/Vedio116.jpg\n",
      "./test_data/Vedio_pic/Vedio61.jpg\n",
      "0.006161928176879883\n",
      "./working/Vedio61.jpg\n",
      "./test_data/Vedio_pic/Vedio106.jpg\n",
      "0.005967378616333008\n",
      "./working/Vedio106.jpg\n",
      "./test_data/Vedio_pic/Vedio120.jpg\n",
      "0.006055355072021484\n",
      "./working/Vedio120.jpg\n",
      "./test_data/Vedio_pic/Vedio80.jpg\n",
      "0.006311893463134766\n",
      "./working/Vedio80.jpg\n",
      "./test_data/Vedio_pic/Vedio34.jpg\n",
      "0.006078958511352539\n",
      "./working/Vedio34.jpg\n",
      "./test_data/Vedio_pic/Vedio52.jpg\n",
      "0.006237983703613281\n",
      "./working/Vedio52.jpg\n",
      "./test_data/Vedio_pic/Vedio113.jpg\n",
      "0.006124734878540039\n",
      "./working/Vedio113.jpg\n",
      "./test_data/Vedio_pic/Vedio60.jpg\n",
      "0.006124973297119141\n",
      "./working/Vedio60.jpg\n",
      "./test_data/Vedio_pic/Vedio57.jpg\n",
      "0.0060770511627197266\n",
      "./working/Vedio57.jpg\n",
      "./test_data/Vedio_pic/Vedio0.jpg\n",
      "0.005986452102661133\n",
      "./working/Vedio0.jpg\n",
      "./test_data/Vedio_pic/Vedio40.jpg\n",
      "0.006040811538696289\n",
      "./working/Vedio40.jpg\n",
      "./test_data/Vedio_pic/Vedio128.jpg\n",
      "0.006170034408569336\n",
      "./working/Vedio128.jpg\n",
      "./test_data/Vedio_pic/Vedio127.jpg\n",
      "0.0061223506927490234\n",
      "./working/Vedio127.jpg\n",
      "./test_data/Vedio_pic/Vedio46.jpg\n",
      "0.00588679313659668\n",
      "./working/Vedio46.jpg\n",
      "./test_data/Vedio_pic/Vedio146.jpg\n",
      "0.006039857864379883\n",
      "./working/Vedio146.jpg\n",
      "./test_data/Vedio_pic/Vedio66.jpg\n",
      "0.0062694549560546875\n",
      "./working/Vedio66.jpg\n",
      "./test_data/Vedio_pic/Vedio112.jpg\n",
      "0.005969524383544922\n",
      "./working/Vedio112.jpg\n",
      "./test_data/Vedio_pic/Vedio118.jpg\n",
      "0.006178617477416992\n",
      "./working/Vedio118.jpg\n",
      "./test_data/Vedio_pic/Vedio26.jpg\n",
      "0.006165742874145508\n",
      "./working/Vedio26.jpg\n",
      "./test_data/Vedio_pic/Vedio33.jpg\n",
      "0.006412506103515625\n",
      "./working/Vedio33.jpg\n",
      "./test_data/Vedio_pic/Vedio105.jpg\n",
      "0.0060503482818603516\n",
      "./working/Vedio105.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_data/Vedio_pic/Vedio147.jpg\n",
      "0.006163120269775391\n",
      "./working/Vedio147.jpg\n",
      "./test_data/Vedio_pic/Vedio20.jpg\n",
      "0.005925416946411133\n",
      "./working/Vedio20.jpg\n",
      "./test_data/Vedio_pic/Vedio43.jpg\n",
      "0.006227016448974609\n",
      "./working/Vedio43.jpg\n",
      "./test_data/Vedio_pic/Vedio73.jpg\n",
      "0.00850820541381836\n",
      "./working/Vedio73.jpg\n",
      "./test_data/Vedio_pic/Vedio77.jpg\n",
      "0.0062253475189208984\n",
      "./working/Vedio77.jpg\n",
      "./test_data/Vedio_pic/Vedio129.jpg\n",
      "0.005964756011962891\n",
      "./working/Vedio129.jpg\n",
      "./test_data/Vedio_pic/Vedio84.jpg\n",
      "0.0060214996337890625\n",
      "./working/Vedio84.jpg\n",
      "./test_data/Vedio_pic/Vedio91.jpg\n",
      "0.00656890869140625\n",
      "./working/Vedio91.jpg\n",
      "./test_data/Vedio_pic/Vedio31.jpg\n",
      "0.005978107452392578\n",
      "./working/Vedio31.jpg\n",
      "./test_data/Vedio_pic/Vedio71.jpg\n",
      "0.005939006805419922\n",
      "./working/Vedio71.jpg\n",
      "./test_data/Vedio_pic/Vedio95.jpg\n",
      "0.00594639778137207\n",
      "./working/Vedio95.jpg\n",
      "./test_data/Vedio_pic/Vedio45.jpg\n",
      "0.006166934967041016\n",
      "./working/Vedio45.jpg\n",
      "./test_data/Vedio_pic/Vedio136.jpg\n",
      "0.007906198501586914\n",
      "./working/Vedio136.jpg\n",
      "./test_data/Vedio_pic/Vedio13.jpg\n",
      "0.0061681270599365234\n",
      "./working/Vedio13.jpg\n",
      "./test_data/Vedio_pic/Vedio142.jpg\n",
      "0.006377458572387695\n",
      "./working/Vedio142.jpg\n",
      "./test_data/Vedio_pic/Vedio99.jpg\n",
      "0.006003618240356445\n",
      "./working/Vedio99.jpg\n",
      "./test_data/Vedio_pic/Vedio49.jpg\n",
      "0.0060367584228515625\n",
      "./working/Vedio49.jpg\n",
      "./test_data/Vedio_pic/Vedio69.jpg\n",
      "0.006230592727661133\n",
      "./working/Vedio69.jpg\n",
      "./test_data/Vedio_pic/Vedio100.jpg\n",
      "0.006066083908081055\n",
      "./working/Vedio100.jpg\n",
      "./test_data/Vedio_pic/Vedio75.jpg\n",
      "0.006185770034790039\n",
      "./working/Vedio75.jpg\n",
      "./test_data/Vedio_pic/Vedio44.jpg\n",
      "0.00594782829284668\n",
      "./working/Vedio44.jpg\n",
      "./test_data/Vedio_pic/Vedio126.jpg\n",
      "0.006016731262207031\n",
      "./working/Vedio126.jpg\n",
      "./test_data/Vedio_pic/Vedio85.jpg\n",
      "0.005960702896118164\n",
      "./working/Vedio85.jpg\n",
      "./test_data/Vedio_pic/Vedio2.jpg\n",
      "0.0061266422271728516\n",
      "./working/Vedio2.jpg\n",
      "./test_data/Vedio_pic/Vedio37.jpg\n",
      "0.006129264831542969\n",
      "./working/Vedio37.jpg\n",
      "./test_data/Vedio_pic/Vedio1.jpg\n",
      "0.006133317947387695\n",
      "./working/Vedio1.jpg\n",
      "./test_data/Vedio_pic/Vedio139.jpg\n",
      "0.0059435367584228516\n",
      "./working/Vedio139.jpg\n",
      "./test_data/Vedio_pic/Vedio74.jpg\n",
      "0.0066680908203125\n",
      "./working/Vedio74.jpg\n",
      "./test_data/Vedio_pic/Vedio111.jpg\n",
      "0.0060024261474609375\n",
      "./working/Vedio111.jpg\n",
      "./test_data/Vedio_pic/Vedio121.jpg\n",
      "0.008704423904418945\n",
      "./working/Vedio121.jpg\n",
      "./test_data/Vedio_pic/Vedio104.jpg\n",
      "0.005964040756225586\n",
      "./working/Vedio104.jpg\n",
      "./test_data/Vedio_pic/Vedio50.jpg\n",
      "0.006128787994384766\n",
      "./working/Vedio50.jpg\n",
      "./test_data/Vedio_pic/Vedio83.jpg\n",
      "0.00603938102722168\n",
      "./working/Vedio83.jpg\n",
      "./test_data/Vedio_pic/Vedio38.jpg\n",
      "0.0059130191802978516\n",
      "./working/Vedio38.jpg\n",
      "./test_data/Vedio_pic/Vedio11.jpg\n",
      "0.006230354309082031\n",
      "./working/Vedio11.jpg\n",
      "./test_data/Vedio_pic/Vedio135.jpg\n",
      "0.0061414241790771484\n",
      "./working/Vedio135.jpg\n",
      "./test_data/Vedio_pic/Vedio148.jpg\n",
      "0.006211042404174805\n",
      "./working/Vedio148.jpg\n",
      "./test_data/Vedio_pic/Vedio122.jpg\n",
      "0.006027698516845703\n",
      "./working/Vedio122.jpg\n",
      "./test_data/Vedio_pic/Vedio29.jpg\n",
      "0.006111860275268555\n",
      "./working/Vedio29.jpg\n",
      "./test_data/Vedio_pic/Vedio143.jpg\n",
      "0.00603485107421875\n",
      "./working/Vedio143.jpg\n",
      "./test_data/Vedio_pic/Vedio6.jpg\n",
      "0.00601959228515625\n",
      "./working/Vedio6.jpg\n",
      "./test_data/Vedio_pic/Vedio72.jpg\n",
      "0.010390520095825195\n",
      "./working/Vedio72.jpg\n",
      "./test_data/Vedio_pic/Vedio3.jpg\n",
      "0.00663304328918457\n",
      "./working/Vedio3.jpg\n",
      "./test_data/Vedio_pic/Vedio115.jpg\n",
      "0.01354217529296875\n",
      "./working/Vedio115.jpg\n",
      "./test_data/Vedio_pic/Vedio145.jpg\n",
      "0.00867915153503418\n",
      "./working/Vedio145.jpg\n",
      "./test_data/Vedio_pic/Vedio22.jpg\n",
      "0.011364221572875977\n",
      "./working/Vedio22.jpg\n",
      "./test_data/Vedio_pic/Vedio102.jpg\n",
      "0.012083292007446289\n",
      "./working/Vedio102.jpg\n",
      "./test_data/Vedio_pic/Vedio56.jpg\n",
      "0.008157491683959961\n",
      "./working/Vedio56.jpg\n",
      "./test_data/Vedio_pic/Vedio92.jpg\n",
      "0.009270668029785156\n",
      "./working/Vedio92.jpg\n",
      "./test_data/Vedio_pic/Vedio23.jpg\n",
      "0.006783485412597656\n",
      "./working/Vedio23.jpg\n",
      "./test_data/Vedio_pic/Vedio131.jpg\n",
      "0.006223917007446289\n",
      "./working/Vedio131.jpg\n",
      "./test_data/Vedio_pic/Vedio132.jpg\n",
      "0.005983114242553711\n",
      "./working/Vedio132.jpg\n",
      "./test_data/Vedio_pic/Vedio21.jpg\n",
      "0.0061686038970947266\n",
      "./working/Vedio21.jpg\n",
      "./test_data/Vedio_pic/Vedio93.jpg\n",
      "0.006754159927368164\n",
      "./working/Vedio93.jpg\n",
      "./test_data/Vedio_pic/Vedio30.jpg\n",
      "0.006204843521118164\n",
      "./working/Vedio30.jpg\n",
      "./test_data/Vedio_pic/Vedio62.jpg\n",
      "0.006635189056396484\n",
      "./working/Vedio62.jpg\n",
      "./test_data/Vedio_pic/Vedio125.jpg\n",
      "0.005999565124511719\n",
      "./working/Vedio125.jpg\n",
      "./test_data/Vedio_pic/Vedio4.jpg\n",
      "0.006180763244628906\n",
      "./working/Vedio4.jpg\n",
      "./test_data/Vedio_pic/Vedio24.jpg\n",
      "0.0059986114501953125\n",
      "./working/Vedio24.jpg\n",
      "./test_data/Vedio_pic/Vedio87.jpg\n",
      "0.0061109066009521484\n",
      "./working/Vedio87.jpg\n",
      "./test_data/Vedio_pic/Vedio53.jpg\n",
      "0.00636744499206543\n",
      "./working/Vedio53.jpg\n",
      "./test_data/Vedio_pic/Vedio103.jpg\n",
      "0.006108522415161133\n",
      "./working/Vedio103.jpg\n",
      "./test_data/Vedio_pic/Vedio97.jpg\n",
      "0.006048679351806641\n",
      "./working/Vedio97.jpg\n",
      "./test_data/Vedio_pic/Vedio98.jpg\n",
      "0.0075817108154296875\n",
      "./working/Vedio98.jpg\n",
      "./test_data/Vedio_pic/Vedio94.jpg\n",
      "0.00843954086303711\n",
      "./working/Vedio94.jpg\n",
      "./test_data/Vedio_pic/Vedio12.jpg\n",
      "0.0072879791259765625\n",
      "./working/Vedio12.jpg\n",
      "./test_data/Vedio_pic/Vedio138.jpg\n",
      "0.006161689758300781\n",
      "./working/Vedio138.jpg\n",
      "./test_data/Vedio_pic/Vedio10.jpg\n",
      "0.006972789764404297\n",
      "./working/Vedio10.jpg\n",
      "./test_data/Vedio_pic/Vedio79.jpg\n",
      "0.006174325942993164\n",
      "./working/Vedio79.jpg\n",
      "./test_data/Vedio_pic/Vedio64.jpg\n",
      "0.0059316158294677734\n",
      "./working/Vedio64.jpg\n",
      "./test_data/Vedio_pic/Vedio35.jpg\n",
      "0.0059850215911865234\n",
      "./working/Vedio35.jpg\n",
      "./test_data/Vedio_pic/Vedio82.jpg\n",
      "0.0062711238861083984\n",
      "./working/Vedio82.jpg\n",
      "./test_data/Vedio_pic/Vedio8.jpg\n",
      "0.00617218017578125\n",
      "./working/Vedio8.jpg\n",
      "./test_data/Vedio_pic/Vedio107.jpg\n",
      "0.005910396575927734\n",
      "./working/Vedio107.jpg\n",
      "./test_data/Vedio_pic/Vedio90.jpg\n",
      "0.005949974060058594\n",
      "./working/Vedio90.jpg\n",
      "./test_data/Vedio_pic/Vedio137.jpg\n",
      "0.005975246429443359\n",
      "./working/Vedio137.jpg\n",
      "./test_data/Vedio_pic/Vedio63.jpg\n",
      "0.006059408187866211\n",
      "./working/Vedio63.jpg\n",
      "./test_data/Vedio_pic/Vedio54.jpg\n",
      "0.00591588020324707\n",
      "./working/Vedio54.jpg\n",
      "./test_data/Vedio_pic/Vedio134.jpg\n",
      "0.0061452388763427734\n",
      "./working/Vedio134.jpg\n",
      "./test_data/Vedio_pic/Vedio32.jpg\n",
      "0.008045196533203125\n",
      "./working/Vedio32.jpg\n",
      "./test_data/Vedio_pic/Vedio76.jpg\n",
      "0.006209850311279297\n",
      "./working/Vedio76.jpg\n",
      "./test_data/Vedio_pic/Vedio108.jpg\n",
      "0.006499767303466797\n",
      "./working/Vedio108.jpg\n",
      "./test_data/Vedio_pic/Vedio130.jpg\n",
      "0.006684064865112305\n",
      "./working/Vedio130.jpg\n",
      "./test_data/Vedio_pic/Vedio89.jpg\n",
      "0.00605320930480957\n",
      "./working/Vedio89.jpg\n",
      "./test_data/Vedio_pic/Vedio27.jpg\n",
      "0.007066249847412109\n",
      "./working/Vedio27.jpg\n",
      "./test_data/Vedio_pic/Vedio110.jpg\n",
      "0.006742238998413086\n",
      "./working/Vedio110.jpg\n",
      "./test_data/Vedio_pic/Vedio36.jpg\n",
      "0.007234096527099609\n",
      "./working/Vedio36.jpg\n",
      "./test_data/Vedio_pic/Vedio28.jpg\n",
      "0.0072743892669677734\n",
      "./working/Vedio28.jpg\n",
      "./test_data/Vedio_pic/Vedio68.jpg\n",
      "0.007046222686767578\n",
      "./working/Vedio68.jpg\n",
      "./test_data/Vedio_pic/Vedio25.jpg\n",
      "0.007970809936523438\n",
      "./working/Vedio25.jpg\n",
      "./test_data/Vedio_pic/Vedio14.jpg\n",
      "0.0060882568359375\n",
      "./working/Vedio14.jpg\n",
      "./test_data/Vedio_pic/Vedio39.jpg\n",
      "0.0072443485260009766\n",
      "./working/Vedio39.jpg\n",
      "./test_data/Vedio_pic/Vedio78.jpg\n",
      "0.006131172180175781\n",
      "./working/Vedio78.jpg\n",
      "./test_data/Vedio_pic/Vedio15.jpg\n",
      "0.006497383117675781\n",
      "./working/Vedio15.jpg\n",
      "./test_data/Vedio_pic/Vedio144.jpg\n",
      "0.005998134613037109\n",
      "./working/Vedio144.jpg\n",
      "./test_data/Vedio_pic/Vedio18.jpg\n",
      "0.006822109222412109\n",
      "./working/Vedio18.jpg\n",
      "./test_data/Vedio_pic/Vedio16.jpg\n",
      "0.006040096282958984\n",
      "./working/Vedio16.jpg\n",
      "./test_data/Vedio_pic/Vedio7.jpg\n",
      "0.0060558319091796875\n",
      "./working/Vedio7.jpg\n",
      "./test_data/Vedio_pic/Vedio101.jpg\n",
      "0.005900859832763672\n",
      "./working/Vedio101.jpg\n",
      "./test_data/Vedio_pic/Vedio117.jpg\n",
      "0.0059511661529541016\n",
      "./working/Vedio117.jpg\n",
      "./test_data/Vedio_pic/Vedio133.jpg\n",
      "0.006084442138671875\n",
      "./working/Vedio133.jpg\n",
      "./test_data/Vedio_pic/Vedio51.jpg\n",
      "0.0060350894927978516\n",
      "./working/Vedio51.jpg\n",
      "./test_data/Vedio_pic/Vedio141.jpg\n",
      "0.006118059158325195\n",
      "./working/Vedio141.jpg\n",
      "./test_data/Vedio_pic/Vedio17.jpg\n",
      "0.006081581115722656\n",
      "./working/Vedio17.jpg\n",
      "./test_data/Vedio_pic/Vedio67.jpg\n",
      "0.0063114166259765625\n",
      "./working/Vedio67.jpg\n",
      "./test_data/Vedio_pic/Vedio124.jpg\n",
      "0.009915828704833984\n",
      "./working/Vedio124.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_data/Vedio_pic/Vedio70.jpg\n",
      "0.006665945053100586\n",
      "./working/Vedio70.jpg\n",
      "./test_data/Vedio_pic/Vedio88.jpg\n",
      "0.006119966506958008\n",
      "./working/Vedio88.jpg\n",
      "./test_data/Vedio_pic/Vedio114.jpg\n",
      "0.00608515739440918\n",
      "./working/Vedio114.jpg\n",
      "./test_data/Vedio_pic/Vedio48.jpg\n",
      "0.005862236022949219\n",
      "./working/Vedio48.jpg\n",
      "./test_data/Vedio_pic/Vedio55.jpg\n",
      "0.009128808975219727\n",
      "./working/Vedio55.jpg\n",
      "./test_data/Vedio_pic/Vedio5.jpg\n",
      "0.006156444549560547\n",
      "./working/Vedio5.jpg\n",
      "./test_data/Vedio_pic/Vedio9.jpg\n",
      "0.008073568344116211\n",
      "./working/Vedio9.jpg\n",
      "./test_data/Vedio_pic/Vedio123.jpg\n",
      "0.0062427520751953125\n",
      "./working/Vedio123.jpg\n",
      "./test_data/Vedio_pic/Vedio47.jpg\n",
      "0.0062563419342041016\n",
      "./working/Vedio47.jpg\n",
      "./test_data/DICM/35.jpg\n",
      "0.07317590713500977\n",
      "./working/35.jpg\n",
      "./test_data/DICM/13.jpg\n",
      "0.00769495964050293\n",
      "./working/13.jpg\n",
      "./test_data/DICM/02.jpg\n",
      "0.005685091018676758\n",
      "./working/02.jpg\n",
      "./test_data/DICM/28.jpg\n",
      "0.0059697628021240234\n",
      "./working/28.jpg\n",
      "./test_data/DICM/39.jpg\n",
      "0.0077893733978271484\n",
      "./working/39.jpg\n",
      "./test_data/DICM/16.jpg\n",
      "0.01598811149597168\n",
      "./working/16.jpg\n",
      "./test_data/DICM/22.jpg\n",
      "0.005727052688598633\n",
      "./working/22.jpg\n",
      "./test_data/DICM/64.jpg\n",
      "0.007619380950927734\n",
      "./working/64.jpg\n",
      "./test_data/DICM/44.jpg\n",
      "0.0077152252197265625\n",
      "./working/44.jpg\n",
      "./test_data/DICM/47.jpg\n",
      "0.005882740020751953\n",
      "./working/47.jpg\n",
      "./test_data/DICM/10.jpg\n",
      "0.0056610107421875\n",
      "./working/10.jpg\n",
      "./test_data/DICM/33.jpg\n",
      "0.008329153060913086\n",
      "./working/33.jpg\n",
      "./test_data/DICM/08.jpg\n",
      "0.005770206451416016\n",
      "./working/08.jpg\n",
      "./test_data/DICM/20.jpg\n",
      "0.0058040618896484375\n",
      "./working/20.jpg\n",
      "./test_data/DICM/42.jpg\n",
      "0.00771021842956543\n",
      "./working/42.jpg\n",
      "./test_data/DICM/54.jpg\n",
      "0.005715131759643555\n",
      "./working/54.jpg\n",
      "./test_data/DICM/nvcamtest_11820_s00_00000.jpg\n",
      "0.005635499954223633\n",
      "./working/nvcamtest_11820_s00_00000.jpg\n",
      "./test_data/DICM/11.jpg\n",
      "0.005766868591308594\n",
      "./working/11.jpg\n",
      "./test_data/DICM/62.jpg\n",
      "0.00570368766784668\n",
      "./working/62.jpg\n",
      "./test_data/DICM/34.jpg\n",
      "0.008384227752685547\n",
      "./working/34.jpg\n",
      "./test_data/DICM/46.jpg\n",
      "0.005845069885253906\n",
      "./working/46.jpg\n",
      "./test_data/DICM/38.jpg\n",
      "0.007627964019775391\n",
      "./working/38.jpg\n",
      "./test_data/DICM/36.jpg\n",
      "0.007916688919067383\n",
      "./working/36.jpg\n",
      "./test_data/DICM/09.jpg\n",
      "0.0056917667388916016\n",
      "./working/09.jpg\n",
      "./test_data/DICM/37.jpg\n",
      "0.005913257598876953\n",
      "./working/37.jpg\n",
      "./test_data/DICM/45.jpg\n",
      "0.0059354305267333984\n",
      "./working/45.jpg\n",
      "./test_data/DICM/21.jpg\n",
      "0.005827903747558594\n",
      "./working/21.jpg\n",
      "./test_data/DICM/53.jpg\n",
      "0.005966663360595703\n",
      "./working/53.jpg\n",
      "./test_data/DICM/07.jpg\n",
      "0.005619525909423828\n",
      "./working/07.jpg\n",
      "./test_data/DICM/05.jpg\n",
      "0.0057430267333984375\n",
      "./working/05.jpg\n",
      "./test_data/DICM/52.jpg\n",
      "0.005842924118041992\n",
      "./working/52.jpg\n",
      "./test_data/DICM/31.jpg\n",
      "0.007835149765014648\n",
      "./working/31.jpg\n",
      "./test_data/DICM/61.jpg\n",
      "0.007569551467895508\n",
      "./working/61.jpg\n",
      "./test_data/DICM/48.jpg\n",
      "0.0057642459869384766\n",
      "./working/48.jpg\n",
      "./test_data/DICM/06.jpg\n",
      "0.00559687614440918\n",
      "./working/06.jpg\n",
      "./test_data/DICM/50.jpg\n",
      "0.005793571472167969\n",
      "./working/50.jpg\n",
      "./test_data/DICM/40.jpg\n",
      "0.007677793502807617\n",
      "./working/40.jpg\n",
      "./test_data/DICM/66.jpg\n",
      "0.005835533142089844\n",
      "./working/66.jpg\n",
      "./test_data/DICM/63.jpg\n",
      "0.005913257598876953\n",
      "./working/63.jpg\n",
      "./test_data/DICM/17.jpg\n",
      "0.005639553070068359\n",
      "./working/17.jpg\n",
      "./test_data/DICM/14.jpg\n",
      "0.005712270736694336\n",
      "./working/14.jpg\n",
      "./test_data/DICM/58.jpg\n",
      "0.0059778690338134766\n",
      "./working/58.jpg\n",
      "./test_data/DICM/04.jpg\n",
      "0.005778789520263672\n",
      "./working/04.jpg\n",
      "./test_data/DICM/19.jpg\n",
      "0.0057489871978759766\n",
      "./working/19.jpg\n",
      "./test_data/DICM/12.jpg\n",
      "0.00567626953125\n",
      "./working/12.jpg\n",
      "./test_data/DICM/29.jpg\n",
      "0.0078008174896240234\n",
      "./working/29.jpg\n",
      "./test_data/DICM/IMG20230221122550.jpg\n",
      "0.005707502365112305\n",
      "./working/IMG20230221122550.jpg\n",
      "./test_data/DICM/67.jpg\n",
      "0.005723714828491211\n",
      "./working/67.jpg\n",
      "./test_data/DICM/32.jpg\n",
      "0.007871627807617188\n",
      "./working/32.jpg\n",
      "./test_data/DICM/49.jpg\n",
      "0.005839109420776367\n",
      "./working/49.jpg\n",
      "./test_data/DICM/27.jpg\n",
      "0.005670070648193359\n",
      "./working/27.jpg\n",
      "./test_data/DICM/26.jpg\n",
      "0.005804777145385742\n",
      "./working/26.jpg\n",
      "./test_data/DICM/55.jpg\n",
      "0.0058438777923583984\n",
      "./working/55.jpg\n",
      "./test_data/DICM/41.jpg\n",
      "0.007975578308105469\n",
      "./working/41.jpg\n",
      "./test_data/DICM/15.jpg\n",
      "0.006059408187866211\n",
      "./working/15.jpg\n",
      "./test_data/DICM/IMG20230221122542.jpg\n",
      "0.0056226253509521484\n",
      "./working/IMG20230221122542.jpg\n",
      "./test_data/DICM/56.jpg\n",
      "0.006400108337402344\n",
      "./working/56.jpg\n",
      "./test_data/DICM/43.jpg\n",
      "0.007603168487548828\n",
      "./working/43.jpg\n",
      "./test_data/DICM/60.jpg\n",
      "0.006110668182373047\n",
      "./working/60.jpg\n",
      "./test_data/DICM/69.jpg\n",
      "0.006455659866333008\n",
      "./working/69.jpg\n",
      "./test_data/DICM/57.jpg\n",
      "0.0058383941650390625\n",
      "./working/57.jpg\n",
      "./test_data/DICM/03.jpg\n",
      "0.005816221237182617\n",
      "./working/03.jpg\n",
      "./test_data/DICM/25.jpg\n",
      "0.00581669807434082\n",
      "./working/25.jpg\n",
      "./test_data/DICM/65.jpg\n",
      "0.005792379379272461\n",
      "./working/65.jpg\n",
      "./test_data/DICM/01.jpg\n",
      "0.005759477615356445\n",
      "./working/01.jpg\n",
      "./test_data/DICM/30.jpg\n",
      "0.005803823471069336\n",
      "./working/30.jpg\n",
      "./test_data/DICM/18.jpg\n",
      "0.005801200866699219\n",
      "./working/18.jpg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "import time\n",
    "\n",
    "\n",
    " \n",
    "def lowlight(image_path):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    data_lowlight = Image.open(image_path)\n",
    "\n",
    "\n",
    "\n",
    "    data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "\n",
    "\n",
    "    data_lowlight = torch.from_numpy(data_lowlight).float()\n",
    "    data_lowlight = data_lowlight.permute(2,0,1)\n",
    "    data_lowlight = data_lowlight.to(device).unsqueeze(0)\n",
    "\n",
    "    DCE_net = enhance_net_nopool().to(device)\n",
    "    DCE_net.load_state_dict(torch.load('./snapshots/Epoch200.pth'))\n",
    "    start = time.time()\n",
    "    _,enhanced_image,_ = DCE_net(data_lowlight)\n",
    "\n",
    "    end_time = (time.time() - start)\n",
    "    print(end_time)\n",
    "    result_path = \"./working/\"\n",
    "    print(result_path+image_path.split(\"/\")[-1])\n",
    "    torchvision.utils.save_image(enhanced_image, result_path+image_path.split(\"/\")[-1])\n",
    "\n",
    "    \n",
    "with torch.no_grad():\n",
    "    filePath = './test_data/'\n",
    "\n",
    "    file_list = os.listdir(filePath)\n",
    "\n",
    "    for file_name in file_list:\n",
    "        test_list = glob.glob(filePath+file_name+\"/*\") \n",
    "        for image in test_list:\n",
    "            # image = image\n",
    "            print(image)\n",
    "            lowlight(image)\n",
    "\n",
    "print(\"finish!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 选择路径视频的合成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish!\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"/home/tx2/Zero-DCE/test_data/Vedio_pic/\")\n",
    "# 要被合成的多张图片所在文件夹\n",
    "# 路径分隔符最好使用“/”,而不是“\\”,“\\”本身有转义的意思；或者“\\\\”也可以。\n",
    "# 因为是文件夹，所以最后还要有一个“/”\n",
    "# VideoWriter是cv2库提供的视频保存方法，将合成的视频保存到该路径中\n",
    "# 'MJPG'意思是支持jpg格式图片\n",
    "# fps = 5代表视频的帧频为5，如果图片不多，帧频最好设置的小一点\n",
    "# (1280,720)是生成的视频像素1280*720，一般要与所使用的图片像素大小一致，否则生成的视频无法播放\n",
    "# 定义保存视频目录名称和压缩格式，像素为1280*720\n",
    "video = cv2.VideoWriter('/home/tx2/Zero-DCE/test_vedio/enhance_test.mp4',cv2.VideoWriter_fourcc(*'mp4v'),30,(1280,720))\n",
    "\n",
    "for i in range(1,len(files)):\n",
    "    #读取图片\n",
    "    img = cv2.imread('/home/tx2/Zero-DCE/working/Vedio%d.jpg'%i)     \n",
    "   \t# resize方法是cv2库提供的更改像素大小的方法\n",
    "    # 将图片转换为1280*720像素大小\n",
    "    #img = cv2.resize(img,(1280,720))\n",
    "    # 写入视频\n",
    "    video.write(img)\n",
    "\n",
    "# 释放资源\n",
    "video.release()\n",
    "print(\"finish!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 打开摄像头录制视频的合成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish!\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(\"/home/tx2/Zero-DCE/test_data/New_vedio/\")\n",
    "# 要被合成的多张图片所在文件夹\n",
    "# 路径分隔符最好使用“/”,而不是“\\”,“\\”本身有转义的意思；或者“\\\\”也可以。\n",
    "# 因为是文件夹，所以最后还要有一个“/”\n",
    "# VideoWriter是cv2库提供的视频保存方法，将合成的视频保存到该路径中\n",
    "# 'MJPG'意思是支持jpg格式图片\n",
    "# fps = 5代表视频的帧频为5，如果图片不多，帧频最好设置的小一点\n",
    "# (1280,720)是生成的视频像素1280*720，一般要与所使用的图片像素大小一致，否则生成的视频无法播放\n",
    "# 定义保存视频目录名称和压缩格式，像素为1280*720\n",
    "video = cv2.VideoWriter('/home/tx2/Zero-DCE/test_vedio/new_test.mp4',cv2.VideoWriter_fourcc(*'mp4v'),30,(1280,720))\n",
    "\n",
    "for i in range(1,len(files)):\n",
    "    #读取图片\n",
    "    img = cv2.imread('/home/tx2/Zero-DCE/test_data/New_vedio/NewVedio%d.jpg'%i)     \n",
    "   \t# resize方法是cv2库提供的更改像素大小的方法\n",
    "    # 将图片转换为1280*720像素大小\n",
    "    #img = cv2.resize(img,(1280,720))\n",
    "    # 写入视频\n",
    "    video.write(img)\n",
    "\n",
    "# 释放资源\n",
    "video.release()\n",
    "\n",
    "video = cv2.VideoWriter('/home/tx2/Zero-DCE/test_vedio/enhance_new_test.mp4',cv2.VideoWriter_fourcc(*'mp4v'),30,(1280,720))\n",
    "\n",
    "for i in range(1,len(files)):\n",
    "    #读取图片\n",
    "    img = cv2.imread('/home/tx2/Zero-DCE/working/NewVedio%d.jpg'%i)     \n",
    "   \t# resize方法是cv2库提供的更改像素大小的方法\n",
    "    # 将图片转换为1280*720像素大小\n",
    "    #img = cv2.resize(img,(1280,720))\n",
    "    # 写入视频\n",
    "    video.write(img)\n",
    "\n",
    "# 释放资源\n",
    "video.release()\n",
    "print(\"finish!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实时视频增强--Torch版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tx2/.local/lib/python3.6/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.042782783508301\n",
      "./working/actual_vedio1.jpg\n",
      "0.009857177734375\n",
      "./working/actual_vedio2.jpg\n",
      "0.00993490219116211\n",
      "./working/actual_vedio3.jpg\n",
      "0.009548187255859375\n",
      "./working/actual_vedio4.jpg\n",
      "0.0075778961181640625\n",
      "./working/actual_vedio5.jpg\n",
      "0.008338689804077148\n",
      "./working/actual_vedio6.jpg\n",
      "0.007040977478027344\n",
      "./working/actual_vedio7.jpg\n",
      "0.00673222541809082\n",
      "./working/actual_vedio8.jpg\n",
      "0.006707191467285156\n",
      "./working/actual_vedio9.jpg\n",
      "0.006955385208129883\n",
      "./working/actual_vedio10.jpg\n",
      "0.0070912837982177734\n",
      "./working/actual_vedio11.jpg\n",
      "0.008150100708007812\n",
      "./working/actual_vedio12.jpg\n",
      "0.010020732879638672\n",
      "./working/actual_vedio13.jpg\n",
      "0.009380102157592773\n",
      "./working/actual_vedio14.jpg\n",
      "0.013527631759643555\n",
      "./working/actual_vedio15.jpg\n",
      "0.01181650161743164\n",
      "./working/actual_vedio16.jpg\n",
      "0.010756492614746094\n",
      "./working/actual_vedio17.jpg\n",
      "0.010182857513427734\n",
      "./working/actual_vedio18.jpg\n",
      "0.008504390716552734\n",
      "./working/actual_vedio19.jpg\n",
      "0.012147665023803711\n",
      "./working/actual_vedio20.jpg\n",
      "0.009931325912475586\n",
      "./working/actual_vedio21.jpg\n",
      "0.010572433471679688\n",
      "./working/actual_vedio22.jpg\n",
      "0.009360074996948242\n",
      "./working/actual_vedio23.jpg\n",
      "0.008907079696655273\n",
      "./working/actual_vedio24.jpg\n",
      "0.010782718658447266\n",
      "./working/actual_vedio25.jpg\n",
      "0.006816387176513672\n",
      "./working/actual_vedio26.jpg\n",
      "0.010885953903198242\n",
      "./working/actual_vedio27.jpg\n",
      "0.012065887451171875\n",
      "./working/actual_vedio28.jpg\n",
      "0.01198267936706543\n",
      "./working/actual_vedio29.jpg\n",
      "0.010885953903198242\n",
      "./working/actual_vedio30.jpg\n",
      "0.011226654052734375\n",
      "./working/actual_vedio31.jpg\n",
      "0.01064157485961914\n",
      "./working/actual_vedio32.jpg\n",
      "0.010432720184326172\n",
      "./working/actual_vedio33.jpg\n",
      "0.009808063507080078\n",
      "./working/actual_vedio34.jpg\n",
      "0.010506153106689453\n",
      "./working/actual_vedio35.jpg\n",
      "0.010210275650024414\n",
      "./working/actual_vedio36.jpg\n",
      "0.010775089263916016\n",
      "./working/actual_vedio37.jpg\n",
      "0.010095834732055664\n",
      "./working/actual_vedio38.jpg\n",
      "0.01011204719543457\n",
      "./working/actual_vedio39.jpg\n",
      "0.009984731674194336\n",
      "./working/actual_vedio40.jpg\n",
      "finish!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "import time\n",
    "\n",
    "\n",
    " \n",
    "def lowlight(image_path):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    data_lowlight = Image.open(image_path)\n",
    "\n",
    "\n",
    "\n",
    "    data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "\n",
    "\n",
    "    data_lowlight = torch.from_numpy(data_lowlight).float()\n",
    "    data_lowlight = data_lowlight.permute(2,0,1)\n",
    "    data_lowlight = data_lowlight.to(device).unsqueeze(0)\n",
    "\n",
    "    DCE_net = enhance_net_nopool().to(device)\n",
    "    DCE_net.load_state_dict(torch.load('./snapshots/Epoch200.pth'))\n",
    "    start = time.time()\n",
    "    _,enhanced_image,_ = DCE_net(data_lowlight)\n",
    "\n",
    "    end_time = (time.time() - start)\n",
    "    print(end_time)\n",
    "    result_path = \"./working/\"\n",
    "    print(result_path+image_path.split(\"/\")[-1])\n",
    "    torchvision.utils.save_image(enhanced_image, result_path+image_path.split(\"/\")[-1])\n",
    "    \n",
    "gst_str = ('nvarguscamerasrc ! '\n",
    "            'video/x-raw(memory:NVMM), '\n",
    "            'width=(int)1280, height=(int)720, '\n",
    "            'format=(string)NV12, framerate=(fraction)30/1 ! '\n",
    "            'nvvidconv flip-method=0 ! '\n",
    "            'video/x-raw, width=(int){}, height=(int){}, '\n",
    "            'format=(string)BGRx ! '\n",
    "            'videoconvert ! appsink').format(1280, 720)  #width, height\n",
    "\n",
    "cap = cv2.VideoCapture(gst_str)\n",
    "if not cap.isOpened():\n",
    "   print('Failed to open camera!')\n",
    "flag = cap.isOpened()\n",
    "i = 1\n",
    "while (flag):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"Capture\", frame)\n",
    "    cv2.imwrite(\"./test_data/actual_vedio/actual_vedio%d.jpg\"%i, frame)\n",
    "    lowlight(\"./test_data/actual_vedio/actual_vedio%d.jpg\"%i)\n",
    "    i=i+1\n",
    "    retval = cap.get(5)\n",
    "    if cv2.waitKey(33) & 0xFF == 27 :\n",
    "        break \n",
    "cap.release() # 释放摄像头\n",
    "cv2.destroyAllWindows()# 释放并销毁窗口  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "files = os.listdir(\"/home/tx2/Zero-DCE/test_data/actual_vedio/\")\n",
    "# 要被合成的多张图片所在文件夹\n",
    "# 路径分隔符最好使用“/”,而不是“\\”,“\\”本身有转义的意思；或者“\\\\”也可以。\n",
    "# 因为是文件夹，所以最后还要有一个“/”\n",
    "# VideoWriter是cv2库提供的视频保存方法，将合成的视频保存到该路径中\n",
    "# 'MJPG'意思是支持jpg格式图片\n",
    "# fps = 5代表视频的帧频为5，如果图片不多，帧频最好设置的小一点\n",
    "# (1280,720)是生成的视频像素1280*720，一般要与所使用的图片像素大小一致，否则生成的视频无法播放\n",
    "# 定义保存视频目录名称和压缩格式，像素为1280*720\n",
    "video = cv2.VideoWriter('/home/tx2/Zero-DCE/test_vedio/actual_test.mp4',cv2.VideoWriter_fourcc(*'mp4v'),30,(1280,720))\n",
    "\n",
    "for i in range(1,len(files)):\n",
    "    #读取图片\n",
    "    img = cv2.imread('./working/actual_vedio%d.jpg'%i)     \n",
    "   \t# resize方法是cv2库提供的更改像素大小的方法\n",
    "    # 将图片转换为1280*720像素大小\n",
    "    #img = cv2.resize(img,(1280,720))\n",
    "    # 写入视频\n",
    "    video.write(img)\n",
    "\n",
    "# 释放资源\n",
    "video.release()\n",
    "print(\"finish!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实时视频增强--TensorRT版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import time\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "gst_str = ('nvarguscamerasrc ! '\n",
    "            'video/x-raw(memory:NVMM), '\n",
    "            'width=(int)480, height=(int)640, '\n",
    "            'format=(string)NV12, framerate=(fraction)30/1 ! '\n",
    "            'nvvidconv flip-method=0 ! '\n",
    "            'video/x-raw, width=(int){}, height=(int){}, '\n",
    "            'format=(string)BGRx ! '\n",
    "            'videoconvert ! appsink').format(480, 640)  #width, height\n",
    "\n",
    "cap = cv2.VideoCapture(gst_str)\n",
    "if not cap.isOpened():\n",
    "   print('Failed to open camera!')\n",
    "flag = cap.isOpened()\n",
    "i = 1\n",
    "\n",
    "def predict(path): # result gets copied into output\n",
    "    #预处理\n",
    "    batch = Image.open(path)\n",
    "    batch = (np.asarray(batch)/255.0)\n",
    "    batch = np.transpose(batch,(2,0,1))\n",
    "    batch=np.ascontiguousarray(batch,dtype=np.float32)\n",
    "    \n",
    "    # transfer input data to device\n",
    "    cuda.memcpy_htod_async(d_input, batch, stream)\n",
    "    # execute model\n",
    "    context.execute_async_v2(bindings, stream.handle, None)  # 此处采用异步推理。如果想要同步推理，需将execute_async_v2替换成execute_v2\n",
    "    # transfer predictions back\n",
    "    cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    "    # syncronize threads\n",
    "    stream.synchronize()\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "# 1. 确定batch size大小，与导出的trt模型保持一致\n",
    "BATCH_SIZE = 1        \n",
    "\n",
    "# 2. 选择是否采用FP16精度，与导出的trt模型保持一致\n",
    "# USE_FP16 = True                                         \n",
    "# target_dtype = np.float16 if USE_FP16 else np.float32   \n",
    "f = open(\"new_DCE_net_onnx_model.trt\", \"rb\")    \n",
    "   # 创建一个Runtime(传入记录器Logger)\n",
    "runtime = trt.Runtime(trt.Logger())\n",
    "engine = runtime.deserialize_cuda_engine(f.read())      # 从文件中加载trt引擎\n",
    "context = engine.create_execution_context()             # 创建context\n",
    "\n",
    "\n",
    "# 4. 分配input和output内存\n",
    "input_batch = np.random.randn(BATCH_SIZE, 720, 1280, 3).astype(np.float32)\n",
    "output = np.empty([BATCH_SIZE, 3,720,1280], dtype = np.float32)\n",
    "\n",
    "d_input = cuda.mem_alloc(1 * input_batch.nbytes)\n",
    "d_output = cuda.mem_alloc(1 * output.nbytes)\n",
    "\n",
    "bindings = [int(d_input), int(d_output)]\n",
    "\n",
    "stream = cuda.Stream()\n",
    "\n",
    "\n",
    "\n",
    "while (flag):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"Capture\", frame)\n",
    "    cv2.imwrite(\"./test_data/actual_vedio_tensorrt/actual_vedio_tensorrt%d.jpg\"%i, frame)\n",
    "    image=predict(\"./test_data/actual_vedio_tensorrt/actual_vedio_tensorrt%d.jpg\"%i)\n",
    "    image=torch.from_numpy(image)\n",
    "    torchvision.utils.save_image(image, './working/actual_vedio_tensorrt%d.jpg'%i)\n",
    "    i=i+1\n",
    "    #retval = cap.get(5)\n",
    "    if cv2.waitKey(33) & 0xFF == 27 :\n",
    "        break \n",
    "cap.release() # 释放摄像头\n",
    "cv2.destroyAllWindows()# 释放并销毁窗口  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# files = os.listdir(\"/home/tx2/Zero-DCE/test_data/actual_vedio_tensorrt/\")\n",
    "# # 要被合成的多张图片所在文件夹\n",
    "# # 路径分隔符最好使用“/”,而不是“\\”,“\\”本身有转义的意思；或者“\\\\”也可以。\n",
    "# # 因为是文件夹，所以最后还要有一个“/”\n",
    "# # VideoWriter是cv2库提供的视频保存方法，将合成的视频保存到该路径中\n",
    "# # 'MJPG'意思是支持jpg格式图片\n",
    "# # fps = 5代表视频的帧频为5，如果图片不多，帧频最好设置的小一点\n",
    "# # (1280,720)是生成的视频像素1280*720，一般要与所使用的图片像素大小一致，否则生成的视频无法播放\n",
    "# # 定义保存视频目录名称和压缩格式，像素为1280*720\n",
    "# video = cv2.VideoWriter('/home/tx2/Zero-DCE/test_vedio/actual_test_tensorrt.mp4',cv2.VideoWriter_fourcc(*'mp4v'),30,(1280,720))\n",
    "\n",
    "# for i in range(1,len(files)):\n",
    "#     #读取图片\n",
    "#     img = cv2.imread('./working/actual_vedio_tensorrt%d.jpg'%i)     \n",
    "#    \t# resize方法是cv2库提供的更改像素大小的方法\n",
    "#     # 将图片转换为1280*720像素大小\n",
    "#     #img = cv2.resize(img,(1280,720))\n",
    "#     # 写入视频\n",
    "#     video.write(img)\n",
    "\n",
    "# # 释放资源\n",
    "# video.release()\n",
    "print(\"finish!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T07:40:54.339904Z",
     "iopub.status.busy": "2023-02-21T07:40:54.339539Z",
     "iopub.status.idle": "2023-02-21T07:45:17.950409Z",
     "shell.execute_reply": "2023-02-21T07:45:17.948707Z",
     "shell.execute_reply.started": "2023-02-21T07:40:54.339874Z"
    }
   },
   "outputs": [],
   "source": [
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find('Conv') != -1:\n",
    "#         m.weight.data.normal_(0.0, 0.02)\n",
    "#     elif classname.find('BatchNorm') != -1:\n",
    "#         m.weight.data.normal_(1.0, 0.02)\n",
    "#         m.bias.data.fill_(0)\n",
    "\n",
    "        \n",
    "        \n",
    "# lowlight_images_path=\"/kaggle/input/zero-dce-pytorchdataset/DICM/\"\n",
    "# lr=0.0001\n",
    "# weight_decay=0.0001\n",
    "# grad_clip_norm=0.1\n",
    "# num_epochs=200\n",
    "# train_batch_size=8\n",
    "# val_batch_size=4\n",
    "# num_workers=2\n",
    "# snapshot_iter=10\n",
    "# snapshots_folder=\"/kaggle/working/snapshots/\"\n",
    "# load_pretrain=False\n",
    "# pretrain_dir=\"snapshots/Epoch99.pth\"\n",
    "\n",
    "# if not os.path.exists(snapshots_folder):\n",
    "#     os.mkdir(snapshots_folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DCE_net = enhance_net_nopool()\n",
    "# DCE_net.to(device)\n",
    "# DCE_net.apply(weights_init)\n",
    "\n",
    "# if load_pretrain == True:\n",
    "#     DCE_net.load_state_dict(torch.load(pretrain_dir))\n",
    "\n",
    "# train_dataset = lowlight_loader(lowlight_images_path)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "\n",
    "# L_color = L_color()\n",
    "# L_spa = L_spa()\n",
    "# L_exp = L_exp(16,0.6)\n",
    "# L_TV = L_TV()\n",
    "\n",
    "\n",
    "# optimizer = torch.optim.Adam(DCE_net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# DCE_net.train()\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     loop=tqdm(train_loader)\n",
    "#     for iteration, img_lowlight in enumerate(loop):\n",
    "\n",
    "#         img_lowlight = img_lowlight.to(device)\n",
    "#         enhanced_image_1,enhanced_image,A  = DCE_net(img_lowlight)\n",
    "        \n",
    "#         Loss_TV = 200*(L_TV(A))\n",
    "\n",
    "#         loss_spa = torch.mean(L_spa(enhanced_image, img_lowlight))\n",
    "\n",
    "#         loss_col = 5*torch.mean(L_color(enhanced_image))\n",
    "\n",
    "#         loss_exp = 10*torch.mean(L_exp(enhanced_image))\n",
    "\n",
    "\n",
    "#         # best_loss\n",
    "#         loss =  Loss_TV + loss_spa + loss_col + loss_exp\n",
    "#         #\n",
    "\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(DCE_net.parameters(),grad_clip_norm)\n",
    "#         optimizer.step()\n",
    "#         loop.set_description(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "#         loop.set_postfix(loss = loss.item())\n",
    "#     if ((epoch+1) % snapshot_iter) == 0:\n",
    "#          torch.save(DCE_net.state_dict(), snapshots_folder + \"Epoch\" + str(epoch) + '.pth') \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "# # parser = argparse.ArgumentParser()\n",
    "\n",
    "# # # Input Parameters\n",
    "# # parser.add_argument('--lowlight_images_path', type=str, default=\"/kaggle/input/zero-dce-pytorchdataset/DICM/\")\n",
    "# # parser.add_argument('--lr', type=float, default=0.0001)\n",
    "# # parser.add_argument('--weight_decay', type=float, default=0.0001)\n",
    "# # parser.add_argument('--grad_clip_norm', type=float, default=0.1)\n",
    "# # parser.add_argument('--num_epochs', type=int, default=200)\n",
    "# # parser.add_argument('--train_batch_size', type=int, default=8)\n",
    "# # parser.add_argument('--val_batch_size', type=int, default=4)\n",
    "# # parser.add_argument('--num_workers', type=int, default=4)\n",
    "# # parser.add_argument('--display_iter', type=int, default=10)\n",
    "# # parser.add_argument('--snapshot_iter', type=int, default=10)\n",
    "# # parser.add_argument('--snapshots_folder', type=str, default=\"snapshots/\")\n",
    "# # parser.add_argument('--load_pretrain', type=bool, default= False)\n",
    "# # parser.add_argument('--pretrain_dir', type=str, default= \"snapshots/Epoch99.pth\")\n",
    "\n",
    "# # config = parser.parse_args()\n",
    "\n",
    "# # if not os.path.exists(config.snapshots_folder):\n",
    "# #     os.mkdir(config.snapshots_folder)\n",
    "\n",
    "\n",
    "# # train(config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T07:46:34.046865Z",
     "iopub.status.busy": "2023-02-21T07:46:34.046499Z",
     "iopub.status.idle": "2023-02-21T07:46:34.056656Z",
     "shell.execute_reply": "2023-02-21T07:46:34.055660Z",
     "shell.execute_reply.started": "2023-02-21T07:46:34.046837Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.save(DCE_net.state_dict(), \"./self_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T07:46:41.821888Z",
     "iopub.status.busy": "2023-02-21T07:46:41.821513Z",
     "iopub.status.idle": "2023-02-21T07:46:45.334005Z",
     "shell.execute_reply": "2023-02-21T07:46:45.332920Z",
     "shell.execute_reply.started": "2023-02-21T07:46:41.821856Z"
    }
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torchvision\n",
    "# import torch.backends.cudnn as cudnn\n",
    "# import torch.optim\n",
    "# import os\n",
    "# import sys\n",
    "# import argparse\n",
    "# import time\n",
    "# import numpy as np\n",
    "# from torchvision import transforms\n",
    "# from PIL import Image\n",
    "# import glob\n",
    "# import time\n",
    "\n",
    "\n",
    " \n",
    "# def comlowlight(image_path):\n",
    "#     device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     data_lowlight = Image.open(image_path)\n",
    "\n",
    "\n",
    "\n",
    "#     data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "\n",
    "\n",
    "#     data_lowlight = torch.from_numpy(data_lowlight).float()\n",
    "#     data_lowlight = data_lowlight.permute(2,0,1)\n",
    "#     data_lowlight = data_lowlight.to(device).unsqueeze(0)\n",
    "\n",
    "#     DCE_net = enhance_net_nopool().to(device)\n",
    "#     DCE_net.load_state_dict(torch.load('./self_model.pth'))\n",
    "#     start = time.time()\n",
    "#     _,enhanced_image,_ = DCE_net(data_lowlight)\n",
    "\n",
    "#     end_time = (time.time() - start)\n",
    "#     print(end_time)\n",
    "#     result_path = \"/kaggle/working/selfmodel/\"\n",
    "#     if not os.path.exists(result_path):\n",
    "#         os.mkdir(result_path)\n",
    "#     print(result_path+image_path.split(\"/\")[-1])\n",
    "#     torchvision.utils.save_image(enhanced_image, result_path+image_path.split(\"/\")[-1])\n",
    "\n",
    "    \n",
    "# with torch.no_grad():\n",
    "#     filePath = '/kaggle/input/zero-dce-pytorchdataset/'\n",
    "\n",
    "#     file_list = os.listdir(filePath)\n",
    "\n",
    "#     for file_name in file_list:\n",
    "#         test_list = glob.glob(filePath+file_name+\"/*\") \n",
    "#         for image in test_list:\n",
    "#             # image = image\n",
    "#             print(image)\n",
    "#             comlowlight(image)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修改测试图片地址就行，测试各种图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-21T06:52:36.467026Z",
     "iopub.status.busy": "2023-02-21T06:52:36.466674Z",
     "iopub.status.idle": "2023-02-21T06:52:41.687385Z",
     "shell.execute_reply": "2023-02-21T06:52:41.686353Z",
     "shell.execute_reply.started": "2023-02-21T06:52:36.466997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 640, 480])\n",
      "./working/01.jpg\n",
      "Prediction cost 10.8285s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tx2/.local/lib/python3.6/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "import time\n",
    "\n",
    "\n",
    " \n",
    "def comlowlight(image_path):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    data_lowlight = Image.open(image_path)\n",
    "\n",
    "\n",
    "\n",
    "    data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "\n",
    "\n",
    "    data_lowlight = torch.from_numpy(data_lowlight).float()\n",
    "    data_lowlight = data_lowlight.permute(2,0,1)\n",
    "    data_lowlight = data_lowlight.to(device).unsqueeze(0)\n",
    "\n",
    "    DCE_net = enhance_net_nopool().to(device)\n",
    "    DCE_net.load_state_dict(torch.load('./snapshots/newEpoch200.pth'))\n",
    "    #start = time.time()\n",
    "    _,enhanced_image,r = DCE_net(data_lowlight)\n",
    "    print(r.shape)\n",
    "    #end_time = (time.time() - start)\n",
    "    #print(end_time)\n",
    "    result_path = \"./working/\"\n",
    "    if not os.path.exists(result_path):\n",
    "        os.mkdir(result_path)\n",
    "    print(result_path+image_path.split(\"/\")[-1])\n",
    "    #torchvision.utils.save_image(enhanced_image, result_path+image_path.split(\"/\")[-1])\n",
    "\n",
    "    \n",
    "with torch.no_grad():\n",
    "    filePath = '/home/tx2/Zero-DCE/test_data/1/'\n",
    "#     file_list = os.listdir(filePath)\n",
    "\n",
    "#     for file_name in file_list:\n",
    "#         test_list = glob.glob(filePath+file_name+\"/*\") \n",
    "#         for image in test_list:\n",
    "#             # image = image\n",
    "#             print(image)\n",
    "#             comlowlight(image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    test_list = glob.glob(filePath+\"/*\") \n",
    "    for image in test_list:\n",
    "        # image = image\n",
    "#         print(image)\n",
    "        t0 = time.time()\n",
    "        comlowlight(image)\n",
    "        t = time.time() - t0\n",
    "        #print(\"finish\")\n",
    "        print(\"Prediction cost {:.4f}s\".format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各种滤波方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"/home/tx2/Zero-DCE/test_data/New_vedio/\")\n",
    "for i in range(1,len(files)):\n",
    "    #读取图片\n",
    "    img = cv2.imread('/home/tx2/Zero-DCE/test_data/New_vedio/NewVedio%d.jpg'%i)     \n",
    "    #img=cv2.blur(img,(5,5))#均值滤波\n",
    "    #img=cv2.boxFilter(img,-1,(5,5),normalize=1)#方框滤波\n",
    "    #img=cv2.GaussianBlur(img,(3,3),0)#高斯滤波\n",
    "    img=cv2.medianBlur(img,3)#中值滤波\n",
    "    cv2.imwrite('/home/tx2/Zero-DCE/test_data/fix_pic/NewVedio%d.jpg'%i, img)\n",
    "\n",
    "# 释放资源"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorrt加速"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction cost 0.4885s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import time\n",
    "from PIL import Image\n",
    "def predict(batch): # result gets copied into output\n",
    "    # transfer input data to device\n",
    "    cuda.memcpy_htod_async(d_input, batch, stream)\n",
    "    # execute model\n",
    "    context.execute_async_v2(bindings, stream.handle, None)  # 此处采用异步推理。如果想要同步推理，需将execute_async_v2替换成execute_v2\n",
    "    # transfer predictions back\n",
    "    cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    "    # syncronize threads\n",
    "    stream.synchronize()\n",
    "\n",
    "    return output\n",
    "# 1. 确定batch size大小，与导出的trt模型保持一致\n",
    "BATCH_SIZE = 1        \n",
    "\n",
    "# 2. 选择是否采用FP16精度，与导出的trt模型保持一致\n",
    "# USE_FP16 = True                                         \n",
    "# target_dtype = np.float16 if USE_FP16 else np.float32   \n",
    "f = open(\"new_DCE_net_onnx_model.trt\", \"rb\")    \n",
    "   # 创建一个Runtime(传入记录器Logger)\n",
    "runtime = trt.Runtime(trt.Logger())\n",
    "engine = runtime.deserialize_cuda_engine(f.read())      # 从文件中加载trt引擎\n",
    "context = engine.create_execution_context()             # 创建context\n",
    "\n",
    "\n",
    "# 4. 分配input和output内存\n",
    "input_batch = np.random.randn(BATCH_SIZE, 720, 1280, 3).astype(np.float32)\n",
    "output = np.empty([BATCH_SIZE, 3,720,1280], dtype = np.float32)\n",
    "\n",
    "d_input = cuda.mem_alloc(1 * input_batch.nbytes)\n",
    "d_output = cuda.mem_alloc(1 * output.nbytes)\n",
    "\n",
    "bindings = [int(d_input), int(d_output)]\n",
    "\n",
    "stream = cuda.Stream()\n",
    "\n",
    "data_lowlight = Image.open(\"/home/tx2/Zero-DCE/test_data/New_vedio/NewVedio214.jpg\")\n",
    "data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "data_lowlight = np.transpose(data_lowlight,(2,0,1))\n",
    "data_lowlight=np.ascontiguousarray(data_lowlight,dtype=np.float32)\n",
    "t0 = time.time()\n",
    "pred=predict(data_lowlight)\n",
    "t = time.time() - t0\n",
    "print(\"Prediction cost {:.4f}s\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction cost 0.4035s\n",
      "Prediction cost 0.4445s\n",
      "Prediction cost 0.3742s\n",
      "Prediction cost 0.3580s\n",
      "Prediction cost 0.3609s\n",
      "Prediction cost 0.3718s\n",
      "Prediction cost 0.3772s\n",
      "Prediction cost 0.3749s\n",
      "Prediction cost 0.3657s\n",
      "Prediction cost 0.3719s\n",
      "Prediction cost 0.3761s\n",
      "Prediction cost 0.3718s\n",
      "Prediction cost 0.3616s\n",
      "Prediction cost 0.3567s\n",
      "Prediction cost 0.3618s\n",
      "Prediction cost 0.3562s\n",
      "Prediction cost 0.3578s\n",
      "Prediction cost 0.3573s\n",
      "Prediction cost 0.3592s\n",
      "Prediction cost 0.3705s\n",
      "Prediction cost 0.3694s\n",
      "Prediction cost 0.3736s\n",
      "Prediction cost 0.3735s\n",
      "Prediction cost 0.3733s\n",
      "Prediction cost 0.3707s\n",
      "Prediction cost 0.3631s\n",
      "Prediction cost 0.3588s\n",
      "Prediction cost 0.3610s\n",
      "Prediction cost 0.3607s\n",
      "Prediction cost 0.3598s\n",
      "Prediction cost 0.3576s\n",
      "Prediction cost 0.3591s\n",
      "Prediction cost 0.3713s\n",
      "Prediction cost 0.3686s\n",
      "Prediction cost 0.3733s\n",
      "Prediction cost 0.3738s\n",
      "Prediction cost 0.3770s\n",
      "Prediction cost 0.3729s\n",
      "Prediction cost 0.3758s\n",
      "Prediction cost 0.3584s\n",
      "Prediction cost 0.3588s\n",
      "Prediction cost 0.3541s\n",
      "Prediction cost 0.3559s\n",
      "Prediction cost 0.3574s\n",
      "Prediction cost 0.3589s\n",
      "Prediction cost 0.3536s\n",
      "Prediction cost 0.3703s\n",
      "Prediction cost 0.4196s\n",
      "Prediction cost 0.3727s\n",
      "Prediction cost 0.3734s\n",
      "Prediction cost 0.3716s\n",
      "Prediction cost 0.3692s\n",
      "Prediction cost 0.3694s\n",
      "Prediction cost 0.3877s\n",
      "Prediction cost 0.3739s\n",
      "Prediction cost 0.3726s\n",
      "Prediction cost 0.3764s\n",
      "Prediction cost 0.4241s\n",
      "Prediction cost 0.4305s\n",
      "Prediction cost 0.3939s\n",
      "Prediction cost 0.4543s\n",
      "Prediction cost 0.4190s\n",
      "Prediction cost 0.3653s\n",
      "Prediction cost 0.3523s\n",
      "Prediction cost 0.3849s\n",
      "Prediction cost 0.3965s\n",
      "Prediction cost 0.3693s\n",
      "Prediction cost 0.3824s\n",
      "Prediction cost 0.3921s\n",
      "Prediction cost 0.3725s\n",
      "Prediction cost 0.3776s\n",
      "Prediction cost 0.3773s\n",
      "Prediction cost 0.3702s\n",
      "Prediction cost 0.3708s\n",
      "Prediction cost 0.3559s\n",
      "Prediction cost 0.3637s\n",
      "Prediction cost 0.3580s\n",
      "Prediction cost 0.3612s\n",
      "Prediction cost 0.3612s\n",
      "Prediction cost 0.3773s\n",
      "Prediction cost 0.3743s\n",
      "Prediction cost 0.3726s\n",
      "Prediction cost 0.3733s\n",
      "Prediction cost 0.3727s\n",
      "Prediction cost 0.3734s\n",
      "Prediction cost 0.4068s\n",
      "Prediction cost 0.3721s\n",
      "Prediction cost 0.4082s\n",
      "Prediction cost 0.3954s\n",
      "Prediction cost 0.4079s\n",
      "Prediction cost 0.3647s\n",
      "Prediction cost 0.3550s\n",
      "Prediction cost 0.3610s\n",
      "Prediction cost 0.3709s\n",
      "Prediction cost 0.3705s\n",
      "Prediction cost 0.3743s\n",
      "Prediction cost 0.3729s\n",
      "Prediction cost 0.3706s\n",
      "Prediction cost 0.4129s\n",
      "Prediction cost 0.4198s\n",
      "Prediction cost 0.3560s\n",
      "Prediction cost 0.4105s\n",
      "Prediction cost 0.3606s\n",
      "Prediction cost 0.3616s\n",
      "Prediction cost 0.3602s\n",
      "Prediction cost 0.3577s\n",
      "Prediction cost 0.3628s\n",
      "Prediction cost 0.3591s\n",
      "Prediction cost 0.3544s\n",
      "Prediction cost 0.3600s\n",
      "Prediction cost 0.3578s\n",
      "Prediction cost 0.3563s\n",
      "Prediction cost 0.3558s\n",
      "Prediction cost 0.3674s\n",
      "Prediction cost 0.3750s\n",
      "Prediction cost 0.3676s\n",
      "Prediction cost 0.3756s\n",
      "Prediction cost 0.3989s\n",
      "Prediction cost 0.4142s\n",
      "Prediction cost 0.3673s\n",
      "Prediction cost 0.3741s\n",
      "Prediction cost 0.3668s\n",
      "Prediction cost 0.3857s\n",
      "Prediction cost 0.3641s\n",
      "Prediction cost 0.3652s\n",
      "Prediction cost 0.3597s\n",
      "Prediction cost 0.3737s\n",
      "Prediction cost 0.4249s\n",
      "Prediction cost 0.3847s\n",
      "Prediction cost 0.4346s\n",
      "Prediction cost 0.3732s\n",
      "Prediction cost 0.3757s\n",
      "Prediction cost 0.4277s\n",
      "Prediction cost 0.4093s\n",
      "Prediction cost 0.4180s\n",
      "Prediction cost 0.4235s\n",
      "Prediction cost 0.3981s\n",
      "Prediction cost 0.4221s\n",
      "Prediction cost 0.4053s\n",
      "Prediction cost 0.4158s\n",
      "Prediction cost 0.4236s\n",
      "Prediction cost 0.3701s\n",
      "Prediction cost 0.3681s\n",
      "Prediction cost 0.3709s\n",
      "Prediction cost 0.3761s\n",
      "Prediction cost 0.3716s\n",
      "Prediction cost 0.3665s\n",
      "Prediction cost 0.3563s\n",
      "Prediction cost 0.3610s\n",
      "Prediction cost 0.3588s\n",
      "Prediction cost 0.3537s\n",
      "Prediction cost 0.3670s\n",
      "Prediction cost 0.3580s\n",
      "Prediction cost 0.3673s\n",
      "Prediction cost 0.3771s\n",
      "Prediction cost 0.3703s\n",
      "Prediction cost 0.3680s\n",
      "Prediction cost 0.3726s\n",
      "Prediction cost 0.3720s\n",
      "Prediction cost 0.4100s\n",
      "Prediction cost 0.3704s\n",
      "Prediction cost 0.3869s\n",
      "Prediction cost 0.3818s\n",
      "Prediction cost 0.3758s\n",
      "Prediction cost 0.3723s\n",
      "Prediction cost 0.3718s\n",
      "Prediction cost 0.4006s\n",
      "Prediction cost 0.3646s\n",
      "Prediction cost 0.3838s\n",
      "Prediction cost 0.3612s\n",
      "Prediction cost 0.3616s\n",
      "Prediction cost 0.3837s\n",
      "Prediction cost 0.3719s\n",
      "Prediction cost 0.3808s\n",
      "Prediction cost 0.3794s\n",
      "Prediction cost 0.3764s\n",
      "Prediction cost 0.3765s\n",
      "Prediction cost 0.3745s\n",
      "Prediction cost 0.3835s\n",
      "Prediction cost 0.4007s\n"
     ]
    }
   ],
   "source": [
    "filePath = '/home/tx2/Zero-DCE/test_data/actual_vedio/'\n",
    "test_list = glob.glob(filePath+\"/*\") \n",
    "for image in test_list:\n",
    "    data_lowlight = Image.open(image)\n",
    "    data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "    data_lowlight = np.transpose(data_lowlight,(2,0,1))\n",
    "    data_lowlight=np.ascontiguousarray(data_lowlight,dtype=np.float32)\n",
    "    t0 = time.time()\n",
    "    pred=predict(data_lowlight)\n",
    "    t = time.time() - t0\n",
    "    print(\"Prediction cost {:.4f}s\".format(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorrt加速 480x640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction cost 0.1467s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import time\n",
    "from PIL import Image\n",
    "def predict(batch): # result gets copied into output\n",
    "    # transfer input data to device\n",
    "    cuda.memcpy_htod_async(d_input, batch, stream)\n",
    "    # execute model\n",
    "    context.execute_async_v2(bindings, stream.handle, None)  # 此处采用异步推理。如果想要同步推理，需将execute_async_v2替换成execute_v2\n",
    "    # transfer predictions back\n",
    "    cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    "    # syncronize threads\n",
    "    stream.synchronize()\n",
    "\n",
    "    return output\n",
    "# 1. 确定batch size大小，与导出的trt模型保持一致\n",
    "BATCH_SIZE = 1        \n",
    "\n",
    "# 2. 选择是否采用FP16精度，与导出的trt模型保持一致\n",
    "# USE_FP16 = True                                         \n",
    "# target_dtype = np.float16 if USE_FP16 else np.float32   \n",
    "f = open(\"DCE_net_onnx_model_480x640.trt\", \"rb\")    \n",
    "   # 创建一个Runtime(传入记录器Logger)\n",
    "runtime = trt.Runtime(trt.Logger())\n",
    "engine = runtime.deserialize_cuda_engine(f.read())      # 从文件中加载trt引擎\n",
    "context = engine.create_execution_context()             # 创建context\n",
    "\n",
    "\n",
    "# 4. 分配input和output内存\n",
    "input_batch = np.random.randn(BATCH_SIZE, 480, 640, 3).astype(np.float32)\n",
    "output = np.empty([BATCH_SIZE, 3,480,640], dtype = np.float32)\n",
    "\n",
    "d_input = cuda.mem_alloc(1 * input_batch.nbytes)\n",
    "d_output = cuda.mem_alloc(1 * output.nbytes)\n",
    "\n",
    "bindings = [int(d_input), int(d_output)]\n",
    "\n",
    "stream = cuda.Stream()\n",
    "\n",
    "data_lowlight = Image.open(\"/home/tx2/Zero-DCE/test_data/DICM/01.jpg\")\n",
    "data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "data_lowlight = np.transpose(data_lowlight,(2,0,1))\n",
    "data_lowlight=np.ascontiguousarray(data_lowlight,dtype=np.float32)\n",
    "t0 = time.time()\n",
    "pred=predict(data_lowlight)\n",
    "t = time.time() - t0\n",
    "print(\"Prediction cost {:.4f}s\".format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16081500053405762\n",
      "0.11444997787475586\n",
      "0.11325883865356445\n",
      "0.12192463874816895\n",
      "0.11071562767028809\n",
      "0.12683391571044922\n",
      "0.11155390739440918\n",
      "0.12220597267150879\n",
      "0.11282849311828613\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    t0 = time.time()\n",
    "    pred=predict(data_lowlight)\n",
    "    t = time.time() - t0\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 保存onnx模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tx2/.local/lib/python3.6/site-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.onnx\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DCE_net = enhance_net_nopool().to(device)\n",
    "DCE_net.load_state_dict(torch.load('//home/tx2/Zero-DCE/snapshots/newEpoch200.pth'))\n",
    "dummy_input=torch.randn(1,3, 480, 640).to(device)\n",
    "torch.onnx.export(DCE_net, dummy_input, \n",
    "                  \"DCE_net_onnx_model_480x640_r.onnx\", verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 时间下采样实时增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import time\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "def predict(batch): # result gets copied into output\n",
    "    # transfer input data to device\n",
    "    cuda.memcpy_htod_async(d_input, batch, stream)\n",
    "    # execute model\n",
    "    context.execute_async_v2(bindings, stream.handle, None)  # 此处采用异步推理。如果想要同步推理，需将execute_async_v2替换成execute_v2\n",
    "    # transfer predictions back\n",
    "    cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    "    # syncronize threads\n",
    "    stream.synchronize()\n",
    "\n",
    "    return output\n",
    "# 1. 确定batch size大小，与导出的trt模型保持一致\n",
    "BATCH_SIZE = 1        \n",
    "\n",
    "# 2. 选择是否采用FP16精度，与导出的trt模型保持一致\n",
    "# USE_FP16 = True                                         \n",
    "# target_dtype = np.float16 if USE_FP16 else np.float32   \n",
    "f = open(\"DCE_net_onnx_model_480x640_r.trt\", \"rb\")    \n",
    "   # 创建一个Runtime(传入记录器Logger)\n",
    "runtime = trt.Runtime(trt.Logger())\n",
    "engine = runtime.deserialize_cuda_engine(f.read())      # 从文件中加载trt引擎\n",
    "context = engine.create_execution_context()             # 创建context\n",
    "\n",
    "\n",
    "# 4. 分配input和output内存\n",
    "input_batch = np.random.randn(BATCH_SIZE, 480, 640, 3).astype(np.float32)\n",
    "output = np.empty( [BATCH_SIZE,24,640,480], dtype = np.float32)\n",
    "\n",
    "d_input = cuda.mem_alloc(1 * input_batch.nbytes)\n",
    "d_output = cuda.mem_alloc(1 * output.nbytes)\n",
    "\n",
    "bindings = [int(d_input), int(d_output)]\n",
    "\n",
    "stream = cuda.Stream()\n",
    "\n",
    "data_lowlight = Image.open(\"/home/tx2/Zero-DCE/test_data/DICM/01.jpg\")\n",
    "data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "data_lowlight = np.transpose(data_lowlight,(2,0,1))\n",
    "data_lowlight=np.ascontiguousarray(data_lowlight,dtype=np.float32)\n",
    "r=predict(data_lowlight)\n",
    "print(r.shape)\n",
    "# r=torch.from_numpy(r)\n",
    "# r1,r2,r3,r4,r5,r6,r7,r8 = torch.split(r, 3, dim=1)\n",
    "\n",
    "# x = Image.open(\"/home/tx2/Zero-DCE/test_data/DICM/01.jpg\")\n",
    "# x = (np.asarray(x)/255.0)\n",
    "# x = torch.from_numpy(x).float()\n",
    "# x = x.permute(2,0,1)\n",
    "# x = x.unsqueeze(0)\n",
    "\n",
    "# x = x + r1*(torch.pow(x,2)-x)\n",
    "# x = x + r2*(torch.pow(x,2)-x)\n",
    "# x = x + r3*(torch.pow(x,2)-x)\n",
    "# enhance_image_1 = x + r4*(torch.pow(x,2)-x)\t\t\n",
    "# x = enhance_image_1 + r5*(torch.pow(enhance_image_1,2)-enhance_image_1)\t\t\n",
    "# x = x + r6*(torch.pow(x,2)-x)\t\n",
    "# x = x + r7*(torch.pow(x,2)-x)\n",
    "# enhance_image = x + r8*(torch.pow(x,2)-x)\n",
    "# torchvision.utils.save_image(enhance_image, './working/tensorrtr8_1.jpg')\n",
    "# print(enhance_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import time\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "gst_str = ('nvarguscamerasrc ! '\n",
    "            'video/x-raw(memory:NVMM), '\n",
    "            'width=(int)480, height=(int)640, '\n",
    "            'format=(string)NV12, framerate=(fraction)20/1 ! '\n",
    "            'nvvidconv flip-method=0 ! '\n",
    "            'video/x-raw, width=(int){}, height=(int){}, '\n",
    "            'format=(string)BGRx ! '\n",
    "            'videoconvert ! appsink').format(480, 640)  #width, height\n",
    "\n",
    "cap = cv2.VideoCapture(gst_str)\n",
    "if not cap.isOpened():\n",
    "   print('Failed to open camera!')\n",
    "flag = cap.isOpened()\n",
    "i = 0\n",
    "\n",
    "def predict(batch): # result gets copied into output\n",
    "    # transfer input data to device\n",
    "    cuda.memcpy_htod_async(d_input, batch, stream)\n",
    "    # execute model\n",
    "    context.execute_async_v2(bindings, stream.handle, None)  # 此处采用异步推理。如果想要同步推理，需将execute_async_v2替换成execute_v2\n",
    "    # transfer predictions back\n",
    "    cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    "    # syncronize threads\n",
    "    stream.synchronize()\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "# 1. 确定batch size大小，与导出的trt模型保持一致\n",
    "BATCH_SIZE = 1        \n",
    "\n",
    "# 2. 选择是否采用FP16精度，与导出的trt模型保持一致\n",
    "# USE_FP16 = True                                         \n",
    "# target_dtype = np.float16 if USE_FP16 else np.float32   \n",
    "f = open(\"DCE_net_onnx_model_480x640_r.trt\", \"rb\")    \n",
    "   # 创建一个Runtime(传入记录器Logger)\n",
    "runtime = trt.Runtime(trt.Logger())\n",
    "engine = runtime.deserialize_cuda_engine(f.read())      # 从文件中加载trt引擎\n",
    "context = engine.create_execution_context()             # 创建context\n",
    "\n",
    "\n",
    "# 4. 分配input和output内存\n",
    "input_batch = np.random.randn(BATCH_SIZE, 480, 640, 3).astype(np.float32)\n",
    "output = np.empty([BATCH_SIZE, 24,640,480], dtype = np.float32)\n",
    "\n",
    "d_input = cuda.mem_alloc(1 * input_batch.nbytes)\n",
    "d_output = cuda.mem_alloc(1 * output.nbytes)\n",
    "\n",
    "bindings = [int(d_input), int(d_output)]\n",
    "stream = cuda.Stream()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "j=0\n",
    "\n",
    "while (flag):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"Capture\", frame)\n",
    "    cv2.imwrite(\"./test_data/actual_vedio_tensorrt/actual_vedio_tensorrt%d.jpg\"%i, frame)\n",
    "    if(i>=60 and i%20==0):\n",
    "#         if(j==0):\n",
    "#             data_lowlight = Image.open(\"./test_data/actual_vedio_tensorrt/actual_vedio_tensorrt%d.jpg\"%(j*5))\n",
    "#             data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "#             data_lowlight = np.transpose(data_lowlight,(2,0,1))\n",
    "#             data_lowlight=np.ascontiguousarray(data_lowlight,dtype=np.float32)\n",
    "#             a0=predict(data_lowlight)\n",
    "#         else:\n",
    "#             a0=a5\n",
    "\n",
    "        data_lowlight = Image.open(\"./test_data/actual_vedio_tensorrt/actual_vedio_tensorrt%d.jpg\"%(j*20))\n",
    "        data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "        data_lowlight = np.transpose(data_lowlight,(2,0,1))\n",
    "        data_lowlight=np.ascontiguousarray(data_lowlight,dtype=np.float32)\n",
    "        a0=predict(data_lowlight)\n",
    "        r=torch.from_numpy(a0)\n",
    "\n",
    "        # j=j+1\n",
    "        # data_lowlight = Image.open(\"./test_data/actual_vedio_tensorrt/actual_vedio_tensorrt%d.jpg\"%(j*10-1))\n",
    "        # data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "        # data_lowlight = np.transpose(data_lowlight,(2,0,1))\n",
    "        # data_lowlight=np.ascontiguousarray(data_lowlight,dtype=np.float32)\n",
    "        # a10=predict(data_lowlight)\n",
    "\n",
    "        # ra10=torch.from_numpy(a10)\n",
    "        r1,r2,r3,r4,r5,r6,r7,r8 = torch.split(r.to(device), 3, dim=1)\n",
    "        for z in range(20):\n",
    "        #     ra0.to(device)\n",
    "        #     ra10.to(device)\n",
    "\n",
    "            #r=(9-z)/9*ra0+(z)/9*ra10\n",
    "\n",
    "            x = Image.open(\"./test_data/actual_vedio_tensorrt/actual_vedio_tensorrt%d.jpg\"%(j*20+z))\n",
    "            x = (np.asarray(x)/255.0)\n",
    "            x = torch.from_numpy(x).float()\n",
    "            x = x.permute(2,0,1)\n",
    "            x = x.to(device).unsqueeze(0)\n",
    "\n",
    "            x = x + r1*(torch.pow(x,2)-x)\n",
    "            x = x + r2*(torch.pow(x,2)-x)\n",
    "            x = x + r3*(torch.pow(x,2)-x)\n",
    "            enhance_image_1 = x + r4*(torch.pow(x,2)-x)\t\t\n",
    "\n",
    "            x = enhance_image_1 + r5*(torch.pow(enhance_image_1,2)-enhance_image_1)\t\t\n",
    "            x = x + r6*(torch.pow(x,2)-x)\t\n",
    "            x = x + r7*(torch.pow(x,2)-x)\n",
    "            enhance_image = x + r8*(torch.pow(x,2)-x)\n",
    "            torchvision.utils.save_image(enhance_image, './final/%d.jpg'%(j*5+z-5))\n",
    "        j=j+1\n",
    "\n",
    "    i=i+1\n",
    "    if cv2.waitKey(33) & 0xFF == 27 :\n",
    "        break \n",
    "cap.release() # 释放摄像头\n",
    "cv2.destroyAllWindows()# 释放并销毁窗口  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "files = os.listdir(\"/home/tx2/Zero-DCE/test_data/actual_vedio_tensorrt/\")\n",
    "# 要被合成的多张图片所在文件夹\n",
    "# 路径分隔符最好使用“/”,而不是“\\”,“\\”本身有转义的意思；或者“\\\\”也可以。\n",
    "# 因为是文件夹，所以最后还要有一个“/”\n",
    "# VideoWriter是cv2库提供的视频保存方法，将合成的视频保存到该路径中\n",
    "# 'MJPG'意思是支持jpg格式图片\n",
    "# fps = 5代表视频的帧频为5，如果图片不多，帧频最好设置的小一点\n",
    "# (1280,720)是生成的视频像素1280*720，一般要与所使用的图片像素大小一致，否则生成的视频无法播放\n",
    "# 定义保存视频目录名称和压缩格式，像素为1280*720\n",
    "video = cv2.VideoWriter('/home/tx2/Zero-DCE/test_vedio/actual_test_tensorrt.mp4',cv2.VideoWriter_fourcc(*'mp4v'),30,(1280,720))\n",
    "\n",
    "for i in range(1,len(files)):\n",
    "    #读取图片\n",
    "    img = cv2.imread('./working/actual_vedio_tensorrt%d.jpg'%i)     \n",
    "   \t# resize方法是cv2库提供的更改像素大小的方法\n",
    "    # 将图片转换为1280*720像素大小\n",
    "    #img = cv2.resize(img,(1280,720))\n",
    "    # 写入视频\n",
    "    video.write(img)\n",
    "\n",
    "# # 释放资源\n",
    "# video.release()\n",
    "print(\"finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "import time\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "gst_str = ('nvarguscamerasrc ! '\n",
    "            'video/x-raw(memory:NVMM), '\n",
    "            'width=(int)480, height=(int)640, '\n",
    "            'format=(string)NV12, framerate=(fraction)20/1 ! '\n",
    "            'nvvidconv flip-method=0 ! '\n",
    "            'video/x-raw, width=(int){}, height=(int){}, '\n",
    "            'format=(string)BGRx ! '\n",
    "            'videoconvert ! appsink').format(480, 640)  #width, height\n",
    "\n",
    "cap = cv2.VideoCapture(gst_str)\n",
    "if not cap.isOpened():\n",
    "   print('Failed to open camera!')\n",
    "flag = cap.isOpened()\n",
    "i = 0\n",
    "\n",
    "def predict(batch): # result gets copied into output\n",
    "    # transfer input data to device\n",
    "    cuda.memcpy_htod_async(d_input, batch, stream)\n",
    "    # execute model\n",
    "    context.execute_async_v2(bindings, stream.handle, None)  # 此处采用异步推理。如果想要同步推理，需将execute_async_v2替换成execute_v2\n",
    "    # transfer predictions back\n",
    "    cuda.memcpy_dtoh_async(output, d_output, stream)\n",
    "    # syncronize threads\n",
    "    stream.synchronize()\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "# 1. 确定batch size大小，与导出的trt模型保持一致\n",
    "BATCH_SIZE = 1        \n",
    "\n",
    "# 2. 选择是否采用FP16精度，与导出的trt模型保持一致\n",
    "# USE_FP16 = True                                         \n",
    "# target_dtype = np.float16 if USE_FP16 else np.float32   \n",
    "f = open(\"DCE_net_onnx_model_480x640_r.trt\", \"rb\")    \n",
    "   # 创建一个Runtime(传入记录器Logger)\n",
    "runtime = trt.Runtime(trt.Logger())\n",
    "engine = runtime.deserialize_cuda_engine(f.read())      # 从文件中加载trt引擎\n",
    "context = engine.create_execution_context()             # 创建context\n",
    "\n",
    "\n",
    "# 4. 分配input和output内存\n",
    "input_batch = np.random.randn(BATCH_SIZE, 480, 640, 3).astype(np.float32)\n",
    "output = np.empty([BATCH_SIZE, 24,640,480], dtype = np.float32)\n",
    "\n",
    "d_input = cuda.mem_alloc(1 * input_batch.nbytes)\n",
    "d_output = cuda.mem_alloc(1 * output.nbytes)\n",
    "\n",
    "bindings = [int(d_input), int(d_output)]\n",
    "stream = cuda.Stream()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "j=0\n",
    "\n",
    "while (flag):\n",
    "    ret, frame = cap.read()\n",
    "    #cv2.imshow(\"Capture\", frame)\n",
    "    cv2.imwrite(\"./test_data/actual_vedio_tensorrt/actual_vedio_tensorrt%d.jpg\"%i, frame)\n",
    "    if(i%20==0):\n",
    "#         if(j==0):\n",
    "#             data_lowlight = Image.open(\"./test_data/actual_vedio_tensorrt/actual_vedio_tensorrt%d.jpg\"%(j*5))\n",
    "#             data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "#             data_lowlight = np.transpose(data_lowlight,(2,0,1))\n",
    "#             data_lowlight=np.ascontiguousarray(data_lowlight,dtype=np.float32)\n",
    "#             a0=predict(data_lowlight)\n",
    "#         else:\n",
    "#             a0=a5\n",
    "\n",
    "        data_lowlight = Image.open(\"./test_data/actual_vedio_tensorrt/actual_vedio_tensorrt%d.jpg\"%(j*20))\n",
    "        data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "        data_lowlight = np.transpose(data_lowlight,(2,0,1))\n",
    "        data_lowlight=np.ascontiguousarray(data_lowlight,dtype=np.float32)\n",
    "        a0=predict(data_lowlight)\n",
    "        r=torch.from_numpy(a0)\n",
    "        r1,r2,r3,r4,r5,r6,r7,r8 = torch.split(r.to(device), 3, dim=1)\n",
    "        j=j+1\n",
    "        #     ra0.to(device)\n",
    "        #     ra10.to(device)\n",
    "\n",
    "            #r=(9-z)/9*ra0+(z)/9*ra10\n",
    "\n",
    "    x = Image.open(\"./test_data/actual_vedio_tensorrt/actual_vedio_tensorrt%d.jpg\"%i)\n",
    "    x = (np.asarray(x)/255.0)\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = x.permute(2,0,1)\n",
    "    x = x.to(device).unsqueeze(0)\n",
    "\n",
    "    x = x + r1*(torch.pow(x,2)-x)\n",
    "    x = x + r2*(torch.pow(x,2)-x)\n",
    "    x = x + r3*(torch.pow(x,2)-x)\n",
    "    enhance_image_1 = x + r4*(torch.pow(x,2)-x)\t\t\n",
    "\n",
    "    x = enhance_image_1 + r5*(torch.pow(enhance_image_1,2)-enhance_image_1)\t\t\n",
    "    x = x + r6*(torch.pow(x,2)-x)\t\n",
    "    x = x + r7*(torch.pow(x,2)-x)\n",
    "    enhance_image = x + r8*(torch.pow(x,2)-x)\n",
    "    torchvision.utils.save_image(enhance_image, './final/%d.jpg'%i)\n",
    "    src=cv2.imread('./final/%d.jpg'%i)\n",
    "    cv2.imshow('input_image', src)\n",
    "    i=i+1\n",
    "    \n",
    "    if cv2.waitKey(33) & 0xFF == 27 :\n",
    "        break \n",
    "cap.release() # 释放摄像头\n",
    "cv2.destroyAllWindows()# 释放并销毁窗口  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# files = os.listdir(\"/home/tx2/Zero-DCE/test_data/actual_vedio_tensorrt/\")\n",
    "# # 要被合成的多张图片所在文件夹\n",
    "# # 路径分隔符最好使用“/”,而不是“\\”,“\\”本身有转义的意思；或者“\\\\”也可以。\n",
    "# # 因为是文件夹，所以最后还要有一个“/”\n",
    "# # VideoWriter是cv2库提供的视频保存方法，将合成的视频保存到该路径中\n",
    "# # 'MJPG'意思是支持jpg格式图片\n",
    "# # fps = 5代表视频的帧频为5，如果图片不多，帧频最好设置的小一点\n",
    "# # (1280,720)是生成的视频像素1280*720，一般要与所使用的图片像素大小一致，否则生成的视频无法播放\n",
    "# # 定义保存视频目录名称和压缩格式，像素为1280*720\n",
    "# video = cv2.VideoWriter('/home/tx2/Zero-DCE/test_vedio/actual_test_tensorrt.mp4',cv2.VideoWriter_fourcc(*'mp4v'),30,(1280,720))\n",
    "\n",
    "# for i in range(1,len(files)):\n",
    "#     #读取图片\n",
    "#     img = cv2.imread('./working/actual_vedio_tensorrt%d.jpg'%i)     \n",
    "#    \t# resize方法是cv2库提供的更改像素大小的方法\n",
    "#     # 将图片转换为1280*720像素大小\n",
    "#     #img = cv2.resize(img,(1280,720))\n",
    "#     # 写入视频\n",
    "#     video.write(img)\n",
    "\n",
    "# # 释放资源\n",
    "# video.release()\n",
    "print(\"finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2069, -0.2491, -0.2688,  ..., -0.2849, -0.2850, -0.2852],\n",
      "          [-0.2853, -0.2854, -0.2854,  ..., -0.2901, -0.2900, -0.2899],\n",
      "          [-0.2898, -0.2897, -0.2897,  ..., -0.2928, -0.2927, -0.2925],\n",
      "          ...,\n",
      "          [-0.2448, -0.2396, -0.2358,  ..., -0.2500, -0.2461, -0.2419],\n",
      "          [-0.2378, -0.2337, -0.2298,  ..., -0.2645, -0.2593, -0.2531],\n",
      "          [-0.2469, -0.2411, -0.2353,  ..., -0.2592, -0.2421, -0.2035]],\n",
      "\n",
      "         [[-0.2285, -0.2645, -0.2846,  ..., -0.3042, -0.3043, -0.3044],\n",
      "          [-0.3045, -0.3046, -0.3046,  ..., -0.3102, -0.3101, -0.3100],\n",
      "          [-0.3100, -0.3099, -0.3098,  ..., -0.3124, -0.3123, -0.3121],\n",
      "          ...,\n",
      "          [-0.2765, -0.2720, -0.2688,  ..., -0.2798, -0.2764, -0.2729],\n",
      "          [-0.2697, -0.2664, -0.2635,  ..., -0.2906, -0.2856, -0.2798],\n",
      "          [-0.2742, -0.2692, -0.2644,  ..., -0.2809, -0.2630, -0.2291]],\n",
      "\n",
      "         [[-0.2792, -0.3055, -0.3253,  ..., -0.3489, -0.3490, -0.3491],\n",
      "          [-0.3491, -0.3492, -0.3492,  ..., -0.3521, -0.3521, -0.3520],\n",
      "          [-0.3520, -0.3519, -0.3518,  ..., -0.3537, -0.3536, -0.3534],\n",
      "          ...,\n",
      "          [-0.3316, -0.3279, -0.3255,  ..., -0.3333, -0.3305, -0.3276],\n",
      "          [-0.3252, -0.3228, -0.3211,  ..., -0.3431, -0.3386, -0.3333],\n",
      "          [-0.3283, -0.3242, -0.3209,  ..., -0.3279, -0.3097, -0.2845]]]])\n"
     ]
    }
   ],
   "source": [
    "print(r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0-5帧0，5算其余用权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "j=0\n",
    "data_lowlight = Image.open(\"./test_data/actual_vedio_tensorrt/actual_vedio_tensorrt%d.jpg\"%(j*20))\n",
    "data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "data_lowlight = np.transpose(data_lowlight,(2,0,1))\n",
    "data_lowlight=np.ascontiguousarray(data_lowlight,dtype=np.float32)\n",
    "a0=predict(data_lowlight)\n",
    "r=torch.from_numpy(a0)\n",
    "\n",
    "# j=j+1\n",
    "# data_lowlight = Image.open(\"./test_data/actual_vedio_tensorrt/actual_vedio_tensorrt%d.jpg\"%(j*10-1))\n",
    "# data_lowlight = (np.asarray(data_lowlight)/255.0)\n",
    "# data_lowlight = np.transpose(data_lowlight,(2,0,1))\n",
    "# data_lowlight=np.ascontiguousarray(data_lowlight,dtype=np.float32)\n",
    "# a10=predict(data_lowlight)\n",
    "\n",
    "# ra10=torch.from_numpy(a10)\n",
    "r1,r2,r3,r4,r5,r6,r7,r8 = torch.split(r.to(device), 3, dim=1)\n",
    "for z in range(20):\n",
    "#     ra0.to(device)\n",
    "#     ra10.to(device)\n",
    "\n",
    "    #r=(9-z)/9*ra0+(z)/9*ra10\n",
    "    \n",
    "    \n",
    "    \n",
    "    x = Image.open(\"./test_data/actual_vedio_tensorrt/actual_vedio_tensorrt%d.jpg\"%(j*20+z))\n",
    "    x = (np.asarray(x)/255.0)\n",
    "    x = torch.from_numpy(x).float()\n",
    "    x = x.permute(2,0,1)\n",
    "    x = x.to(device).unsqueeze(0)\n",
    "    \n",
    "    x = x + r1*(torch.pow(x,2)-x)\n",
    "    x = x + r2*(torch.pow(x,2)-x)\n",
    "    x = x + r3*(torch.pow(x,2)-x)\n",
    "    enhance_image_1 = x + r4*(torch.pow(x,2)-x)\t\t\n",
    "    \n",
    "    x = enhance_image_1 + r5*(torch.pow(enhance_image_1,2)-enhance_image_1)\t\t\n",
    "    x = x + r6*(torch.pow(x,2)-x)\t\n",
    "    x = x + r7*(torch.pow(x,2)-x)\n",
    "    enhance_image = x + r8*(torch.pow(x,2)-x)\n",
    "    torchvision.utils.save_image(enhance_image, './final/%d.jpg'%(j*20+z))\n",
    "    \n",
    "    src=cv2.imread('./final/%d.jpg'%(j*20+z))       \n",
    "    cv2.imshow('input_image', src)\n",
    "    cv2.waitKey(100)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
